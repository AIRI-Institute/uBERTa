{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a6693a8-b2d0-4eb1-a0ec-f2a1a194f04b",
   "metadata": {},
   "source": [
    "# Compare predictions\n",
    "\n",
    "Here, we'll compare our predictions with those by other authors. \n",
    "We'll treat the combination of validation and testing datasets as ground truth and check how well other authors predicted TISs across these data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fca1f8fa-056a-4e8a-8a95-6695b12bf422",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "This notebook requires:\n",
    "- [hg38.fa]()\n",
    "- [Our predictions](); either download or go through `predict_5UTR.ipynb`\n",
    "- \"uORF_annotation_hg38.csv\" from [Scholtz et. al](https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0222459)\n",
    "- \"Supplemental_Data_Tables_.xlsx\" from [McGillivray et. al](https://academic.oup.com/nar/article/46/7/3326/4942470)\n",
    "- \"elife-08890-supp1-v2.xlsx\" from [Ji et. al](https://elifesciences.org/articles/08890)\n",
    "\n",
    "Tables from the papers above can be obtained via [this link](https://drive.google.com/file/d/1o1YhRuF4Dp122NWSmcehiLTwf68jwLnK/view?usp=sharing). Unpack the files and place them into the `data` directory (or provide paths manually below).\n",
    "```\n",
    "data\n",
    "|____hg38.fa\n",
    "|____predictions_5UTR.tsv\n",
    "|____others\n",
    "| |____elife-08890-supp1-v2.xlsx\n",
    "| |____uORF_annotation_hg38.csv\n",
    "| |____Supplemental_Data_Tables_.xlsx\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "eeaf3294-3c7e-4e04-8d9a-cd3c9faf9dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from more_itertools import unzip\n",
    "from pyliftover import LiftOver\n",
    "from sklearn.metrics import f1_score, recall_score, precision_score\n",
    "from tqdm.auto import tqdm\n",
    "from uBERTa.utils import Ref, reverse_complement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6ef5109-d87a-47e3-b2f2-c2ed8d053ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE = Path('../data')\n",
    "BASE.mkdir(exist_ok=True)\n",
    "\n",
    "REF = BASE / 'hg38.fa'\n",
    "SCHOLTZ = BASE / 'others' / 'uORF_annotation_hg38.csv'\n",
    "JI = BASE / 'others' / 'elife-08890-supp1-v2.xlsx'\n",
    "GIL = BASE / 'others' / 'Supplemental_Data_Tables_.xlsx'\n",
    "PRED = BASE / 'predictions.tsv'\n",
    "\n",
    "VALID_START = ('ACG', 'ATC', 'ATG', 'ATT', 'CTG', 'GTG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "058706dd-7c9e-4eeb-9706-e90622f02282",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref = Ref(REF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "3f88400c-9a34-4753-8b9f-6de2ccb7cac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_codons(df, ref):\n",
    "    \"\"\"\n",
    "    Given a table with at columns \"Chrom\", \"Start\", \"Strand\", fetch sequences\n",
    "        of regions [Start, Start + 3] for a each row.\n",
    "    For \"-\" strand sequences, take reverse complements.\n",
    "    \"\"\"\n",
    "    handle_seq = lambda seq, strand: (\n",
    "        seq.upper() if strand == '+' else reverse_complement(seq).upper())\n",
    "    return [\n",
    "        handle_seq(\n",
    "            ref.fetch(chrom, start, start + 3), strand) \n",
    "        for _, chrom, start, strand in \n",
    "        tqdm(\n",
    "            df[['Chrom', 'Start', 'Strand']].itertuples(), \n",
    "            total=len(df), desc='Fetching')\n",
    "    ]\n",
    "\n",
    "def lift_starts(df):\n",
    "    \"\"\"\n",
    "    Lift \"Start\" coordinates from hg19 to hg38.\n",
    "    \"\"\"\n",
    "    def convert(*args):\n",
    "        conv_list = lo.convert_coordinate(*args)\n",
    "        if conv_list:\n",
    "            return conv_list[0][1]\n",
    "        return np.nan\n",
    "    \n",
    "    lo = LiftOver('hg19', 'hg38')\n",
    "    return [\n",
    "        convert(*x[1:]) for x in \n",
    "        df[['Chrom', 'Start', 'Strand']].itertuples()]\n",
    "\n",
    "def offset_starts(df, tot_offset=-1, neg_offset=-2):\n",
    "    \"\"\"\n",
    "    Offset start sites depending on a strand so they match our convention, \n",
    "    i.e., 0-based coordinates with \"Start\" pointing at the first nucleotide of a start codon.\n",
    "    The latter is inverted along with the sequence when the strand is negative, \n",
    "    e.g., CAT 1,2,3 -> ATG 3,2,1 => Start=3\n",
    "    \"\"\"\n",
    "    return [\n",
    "        (end + neg_offset if strand == '-' else start) + tot_offset \n",
    "        for _, start, end, strand in \n",
    "        df[['Start', 'End', 'Strand']].itertuples()]\n",
    "\n",
    "def lift_and_fetch(df, ref):\n",
    "    df = df.copy()\n",
    "    df['Start'] = lift_starts(df)\n",
    "    df = df[~df.Start.isna()]\n",
    "    df['Start'] = df['Start'].astype(int)\n",
    "    df['CodonFetched'] = fetch_codons(df, ref)\n",
    "    return df\n",
    "\n",
    "def filter_codons(df, valid=VALID_START):\n",
    "    \"\"\"\n",
    "    When \"Codon\" column is present, filter to rows where manually fetched \n",
    "        codon matches the expected codon.\n",
    "    Filter to rows where codon is among the `valid` sequence of codons.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    if 'Codon' in df.columns and 'CodonFetched' in df.columns:\n",
    "        idx = df.Codon != df.CodonFetched\n",
    "        print(f'Non-matching codons: {idx.sum()}')\n",
    "        df = df[~idx]\n",
    "        df = df.drop(columns='CodonFetched')\n",
    "    idx = ~df.Codon.isin(valid)\n",
    "    print(f'Invalid start codons: {idx.sum()}')\n",
    "    df = df[~idx]\n",
    "    return df\n",
    "\n",
    "def calc_pred_scores(y_true, y_pred):\n",
    "    return {\n",
    "        'f1': f1_score(y_true, y_pred), \n",
    "        'prc': precision_score(y_true, y_pred), \n",
    "        'rec': recall_score(y_true, y_pred)\n",
    "    }\n",
    "\n",
    "def parse_ji(path, ref):\n",
    "    df = pd.read_excel(\n",
    "        path, sheet_name='uORF', usecols=[0, 2, 3, 4, 5], \n",
    "        names=['Gene', 'Chrom', 'Strand', 'Start', 'End']\n",
    "    )\n",
    "    df = df[df.Chrom.apply(lambda x: '_' not in x)]\n",
    "    # Offset for the negative strand is -3, total offset is zero\n",
    "    df['Start'] = offset_starts(df, 0, -3)\n",
    "    df = lift_and_fetch(df, ref)\n",
    "    df = df.rename(columns={'CodonFetched': 'Codon'}).drop(columns='End')\n",
    "    df = filter_codons(df)\n",
    "    return df\n",
    "\n",
    "def parse_scholtz(path, ref):\n",
    "    df = pd.read_csv(\n",
    "        path, skiprows=1,\n",
    "        usecols=[2, 3, 4, 5, 7, 8],\n",
    "        names=['Chrom', 'Start', 'End', 'GeneID', 'Strand', 'Codon']\n",
    "    )\n",
    "    # Offset for the negative strand is -2, total offset is -1, no lifting is needed.\n",
    "    df['Start'] = offset_starts(df)\n",
    "    df['CodonFetched'] = fetch_codons(df, ref)\n",
    "    df = filter_codons(df)\n",
    "    df['GeneID'] = df['GeneID'].apply(lambda x: x.split('.')[0])\n",
    "    df = df.drop(columns='End')\n",
    "    return df\n",
    "\n",
    "def parse_gil(path, ref):\n",
    "    df = pd.read_excel(\n",
    "        path, sheet_name='Supplemental_Table_4', \n",
    "        usecols=[0, 2, 3, 4, 5, 6], skiprows=3,\n",
    "        names=['ID', 'Codon', 'Chrom', 'Strand', 'Start', 'End']\n",
    "    )\n",
    "    df['TranscriptID'] = df['ID'].apply(lambda x: x.split('.')[0])\n",
    "    df = df.drop(columns='ID')\n",
    "    idx = df.Strand == '-'\n",
    "    # For + strand, offset by -1, for - strand, offset by -3\n",
    "    df.loc[~idx, 'Start'] = df.loc[~idx, 'Start'] - 1\n",
    "    df.loc[idx, 'Start'] = df.loc[idx, 'Start'] - 3\n",
    "    # Lift coordinates and filter\n",
    "    df = lift_and_fetch(df, ref)\n",
    "    df = filter_codons(df)\n",
    "    df = df.drop(columns='End')\n",
    "    return df\n",
    "\n",
    "def parse_pred(path):\n",
    "    \"\"\"\n",
    "    Read the dataset with predictions and filter to Test and Val datasets.\n",
    "    \n",
    "    Offset start coordinates. \n",
    "    In our convention, we used 0-based coordinates with \n",
    "        \"Start\" pointing at the first nucleotide of a start codon.\n",
    "    The latter was inverted along with the sequence when the strand is negative, \n",
    "        e.g., CAT 1,2,3 -> ATG 3,2,1 => Start=3\n",
    "    Now, we offset (back) the start by -2 so that it always points \n",
    "        to the first nucleotide of the + strand (so Start=1 in the above example).\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(path, sep='\\t')\n",
    "    df = df[df.Dataset.isin(['Test', 'Val'])]\n",
    "    idx = df.Strand == '-'\n",
    "    df.loc[idx, 'Start'] = df.loc[idx, 'Start'] - 2\n",
    "    return df\n",
    "\n",
    "def annotate_predictions(df):\n",
    "    df = df.copy()\n",
    "    df['PredictionType'] = 'TP'\n",
    "    df.loc[(df.y_true == 1) & (df.y_pred == 0), 'PredictionType'] = 'FN'\n",
    "    df.loc[(df.y_true == 0) & (df.y_pred == 1), 'PredictionType'] = 'FP'\n",
    "    df.loc[(df.y_true == 0) & (df.y_pred == 0), 'PredictionType'] = 'TN'\n",
    "    return df\n",
    "\n",
    "def merge_and_score(\n",
    "    df_pred, df_comp, df_comp_name, \n",
    "    on=['Chrom', 'Strand', 'Start', 'Codon']\n",
    "):\n",
    "    df_comp = df_comp.copy()\n",
    "    df_pred = df_pred.copy()\n",
    "    df_comp['Dataset'] = df_comp_name\n",
    "    df = df_pred.merge(\n",
    "        df_comp, how='left', on=on, suffixes=['_pred', '_comp'])\n",
    "    print(f'Merged size: {len(df)}')\n",
    "    comp_codons = set(df_comp.Codon)\n",
    "    df = df[df.Codon.isin(comp_codons)]\n",
    "    print(f'Filtered to {comp_codons} start codons: {len(df)}')\n",
    "    df['y_pred'] = 1\n",
    "    df.loc[df.Dataset_comp.isna(), 'y_pred'] = 0\n",
    "    df = annotate_predictions(df)\n",
    "    idx_of_codons = ((codon, df.Codon == codon) for codon in comp_codons)\n",
    "    scores = {codon: calc_pred_scores(df[idx].y_true, df[idx].y_pred) \n",
    "              for codon, idx in idx_of_codons}\n",
    "    return df, scores\n",
    "\n",
    "def unravel_scores(scores):\n",
    "    for ds_name, ds_vs in scores.items():\n",
    "        for codon_name, codon_scores in ds_vs.items():\n",
    "            for score_name, score_val in codon_scores.items():\n",
    "                yield ds_name, codon_name, score_name, score_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae3d3d9a-4772-47e3-ab1e-ab7898307cd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b0dd810c6654e748b3f607232a6fe40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching:   0%|          | 0/1933 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-matching codons: 0\n",
      "Invalid start codons: 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e4333f331e44e4ca9ffe5aa263b868e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching:   0%|          | 0/188787 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-matching codons: 792\n",
      "Invalid start codons: 33166\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc943dfa116846cbbeff8a207e9cf51f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching:   0%|          | 0/6614 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid start codons: 563\n"
     ]
    }
   ],
   "source": [
    "scholtz = parse_scholtz(SCHOLTZ, ref)\n",
    "gil = parse_gil(GIL, ref)\n",
    "ji = parse_ji(JI, ref)\n",
    "pred = parse_pred(PRED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "29745ec0-1a74-4fa7-b082-d7d4eb7afc1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged size: 36183\n",
      "Filtered to {'ATG'} start codons: 4337\n",
      "Merged size: 36359\n",
      "Filtered to {'GTG', 'ACG', 'ATC', 'ATG', 'CTG', 'ATT'} start codons: 36359\n",
      "Merged size: 36187\n",
      "Filtered to {'GTG', 'CTG', 'ATC', 'ATG'} start codons: 28482\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ivan/miniconda3/envs/orf/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "ds_names = ['Scholtz', 'McGillivray', 'Ji']\n",
    "merged_dfs, scores = map(\n",
    "    list,\n",
    "    unzip(merge_and_score(pred, ds, ds_name) for ds, ds_name in \n",
    "     zip([scholtz, gil, ji], ds_names)))\n",
    "scores = {ds_name: s for ds_name, s in zip(ds_names, scores)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "31616552-9044-4847-90cb-d11c22bcb3b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scores = pd.DataFrame(\n",
    "    unravel_scores(scores), \n",
    "    columns=['Dataset', 'Codon', 'Score', 'Value']\n",
    ").sort_values(\n",
    "    ['Dataset', 'Codon']\n",
    ")\n",
    "df_scores['Value'] = df_scores['Value'].round(2)\n",
    "df_scores = df_scores.pivot(['Dataset', 'Codon'], ['Score'], ['Value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "35ed4948-78d8-42c5-a00f-5b91bf0e3d0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">Value</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Score</th>\n",
       "      <th>f1</th>\n",
       "      <th>prc</th>\n",
       "      <th>rec</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dataset</th>\n",
       "      <th>Codon</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">Ji</th>\n",
       "      <th>ATC</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ATG</th>\n",
       "      <td>0.40</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CTG</th>\n",
       "      <td>0.06</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GTG</th>\n",
       "      <td>0.09</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">McGillivray</th>\n",
       "      <th>ACG</th>\n",
       "      <td>0.12</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ATC</th>\n",
       "      <td>0.09</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ATG</th>\n",
       "      <td>0.33</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ATT</th>\n",
       "      <td>0.08</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CTG</th>\n",
       "      <td>0.16</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GTG</th>\n",
       "      <td>0.11</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Scholtz</th>\n",
       "      <th>ATG</th>\n",
       "      <td>0.28</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Value            \n",
       "Score                f1   prc   rec\n",
       "Dataset     Codon                  \n",
       "Ji          ATC    0.00  0.00  0.00\n",
       "            ATG    0.40  0.62  0.29\n",
       "            CTG    0.06  0.19  0.04\n",
       "            GTG    0.09  0.22  0.06\n",
       "McGillivray ACG    0.12  0.07  0.53\n",
       "            ATC    0.09  0.05  0.55\n",
       "            ATG    0.33  0.29  0.40\n",
       "            ATT    0.08  0.05  0.54\n",
       "            CTG    0.16  0.09  0.49\n",
       "            GTG    0.11  0.06  0.50\n",
       "Scholtz     ATG    0.28  0.64  0.18"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ee0ebee2-e6a4-4163-a658-53a1a996ad6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{llrrr}\n",
      "\\toprule\n",
      "        & {} & \\multicolumn{3}{l}{Value} \\\\\n",
      "        & Score &    f1 &   prc &   rec \\\\\n",
      "Dataset & Codon &       &       &       \\\\\n",
      "\\midrule\n",
      "Ji & ATC &  0.00 &  0.00 &  0.00 \\\\\n",
      "        & ATG &  0.40 &  0.62 &  0.29 \\\\\n",
      "        & CTG &  0.06 &  0.19 &  0.04 \\\\\n",
      "        & GTG &  0.09 &  0.22 &  0.06 \\\\\n",
      "McGillivray & ACG &  0.12 &  0.07 &  0.53 \\\\\n",
      "        & ATC &  0.09 &  0.05 &  0.55 \\\\\n",
      "        & ATG &  0.33 &  0.29 &  0.40 \\\\\n",
      "        & ATT &  0.08 &  0.05 &  0.54 \\\\\n",
      "        & CTG &  0.16 &  0.09 &  0.49 \\\\\n",
      "        & GTG &  0.11 &  0.06 &  0.50 \\\\\n",
      "Scholtz & ATG &  0.28 &  0.64 &  0.18 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_18534/3791684201.py:1: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  print(df_scores.to_latex())\n"
     ]
    }
   ],
   "source": [
    "print(df_scores.to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "e6233c92-367e-483d-94e2-a154489c5a50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scholtz\n",
      "               Start              \n",
      "PredictionType    FN  FP    TN  TP\n",
      "Codon                             \n",
      "ATG              267  33  3978  59\n",
      "\n",
      "McGillivray\n",
      "               Start                 \n",
      "PredictionType    FN    FP    TN   TP\n",
      "Codon                                \n",
      "ACG               37   552  2271   42\n",
      "ATC               20   462  3597   24\n",
      "ATG              197   331  3689  132\n",
      "ATT               18   438  4358   21\n",
      "CTG              191  1745  9967  181\n",
      "GTG               78  1184  6747   77\n",
      "\n",
      "Ji\n",
      "                Start                     \n",
      "PredictionType     FN    FP       TN    TP\n",
      "Codon                                     \n",
      "ATC              40.0   NaN   4049.0   NaN\n",
      "ATG             231.0  57.0   3954.0  95.0\n",
      "CTG             352.0  54.0  11592.0  13.0\n",
      "GTG             141.0  31.0   7864.0   9.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for name, _df in zip(ds_names, merged_dfs):\n",
    "    counts = _df[\n",
    "        ['Codon', 'PredictionType', 'Start']\n",
    "    ].sort_values(\n",
    "        'Codon'\n",
    "    ).groupby(\n",
    "        ['Codon', 'PredictionType'], as_index=False\n",
    "    ).count().pivot(['Codon'], ['PredictionType'], ['Start'])\n",
    "    print(name, counts, sep='\\n', end='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69bc4100-3444-4b62-9cf7-9cc75006ec9f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
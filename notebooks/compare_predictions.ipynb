{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a6693a8-b2d0-4eb1-a0ec-f2a1a194f04b",
   "metadata": {},
   "source": [
    "# Compare predictions\n",
    "\n",
    "Here, we'll compare our predictions with those by other authors. \n",
    "We'll treat the combination of validation and testing datasets as ground truth and check how well other authors predicted TISs across these data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fca1f8fa-056a-4e8a-8a95-6695b12bf422",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Prerequisites\n",
    "\n",
    "This notebook requires:\n",
    "- [hg38.fa]()\n",
    "- [Our predictions](); either download or go through `predict_5UTR.ipynb`\n",
    "- \"uORF_annotation_hg38.csv\" from [Scholtz et. al](https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0222459)\n",
    "- \"Supplemental_Data_Tables_.xlsx\" from [McGillivray et. al](https://academic.oup.com/nar/article/46/7/3326/4942470)\n",
    "- \"elife-08890-supp1-v2.xlsx\" from [Ji et. al](https://elifesciences.org/articles/08890)\n",
    "\n",
    "Tables from the papers above can be obtained via [this link](https://drive.google.com/file/d/1o1YhRuF4Dp122NWSmcehiLTwf68jwLnK/view?usp=sharing). Unpack the files and place them into the `data` directory (or provide paths manually below).\n",
    "```\n",
    "data\n",
    "|____hg38.fa\n",
    "|____predictions_5UTR_v4.7.csv\n",
    "|____others\n",
    "| |____elife-08890-supp1-v2.xlsx\n",
    "| |____uORF_annotation_hg38.csv\n",
    "| |____Supplemental_Data_Tables_.xlsx\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eeaf3294-3c7e-4e04-8d9a-cd3c9faf9dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from more_itertools import unzip\n",
    "from pyliftover import LiftOver\n",
    "from sklearn.metrics import f1_score, recall_score, precision_score, balanced_accuracy_score\n",
    "from tqdm.auto import tqdm\n",
    "from uBERTa.base import VALID_START\n",
    "from uBERTa.utils import Ref, reverse_complement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6ef5109-d87a-47e3-b2f2-c2ed8d053ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE = Path('../data')\n",
    "BASE.mkdir(exist_ok=True)\n",
    "\n",
    "REF = BASE / 'hg38.fa'\n",
    "SCHOLTZ = BASE / 'others' / 'uORF_annotation_hg38.csv'\n",
    "JI = BASE / 'others' / 'elife-08890-supp1-v2.xlsx'\n",
    "GIL = BASE / 'others' / 'Supplemental_Data_Tables_.xlsx'\n",
    "PRED = BASE / 'XGB' / 'predictions_5UTR_v4.7.csv'\n",
    "\n",
    "VALID_START = VALID_START"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "058706dd-7c9e-4eeb-9706-e90622f02282",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref = Ref(REF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3f88400c-9a34-4753-8b9f-6de2ccb7cac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_codons(df, ref):\n",
    "    \"\"\"\n",
    "    Given a table with at columns \"Chrom\", \"Start\", \"Strand\", fetch sequences\n",
    "        of regions [Start, Start + 3] for a each row.\n",
    "    For \"-\" strand sequences, take reverse complements.\n",
    "    \"\"\"\n",
    "    handle_seq = lambda seq, strand: (\n",
    "        seq.upper() if strand == '+' else reverse_complement(seq).upper())\n",
    "    return [\n",
    "        handle_seq(\n",
    "            ref.fetch(chrom, start, start + 3), strand) \n",
    "        for chrom, start, strand in \n",
    "        tqdm(\n",
    "            df[['Chrom', 'Start', 'Strand']].itertuples(index=False), \n",
    "            total=len(df), desc='Fetching')\n",
    "    ]\n",
    "\n",
    "def filter_codons(df, valid=VALID_START):\n",
    "    \"\"\"\n",
    "    When \"Codon\" column is present, filter to rows where manually fetched \n",
    "        codon matches the expected codon.\n",
    "    Filter to rows where codon is among the `valid` sequence of codons.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    if 'Codon' in df.columns and 'CodonFetched' in df.columns:\n",
    "        idx = df.Codon != df.CodonFetched\n",
    "        print(f'Non-matching codons: {idx.sum()}')\n",
    "        df = df[~idx]\n",
    "        df = df.drop(columns='CodonFetched')\n",
    "    idx = ~df.Codon.isin(valid)\n",
    "    print(f'Invalid start codons: {idx.sum()}')\n",
    "    df = df[~idx]\n",
    "    return df\n",
    "\n",
    "def lift_starts(df):\n",
    "    \"\"\"\n",
    "    Lift \"Start\" coordinates from hg19 to hg38.\n",
    "    \"\"\"\n",
    "    def convert(*args):\n",
    "        conv_list = lo.convert_coordinate(*args)\n",
    "        if conv_list:\n",
    "            return conv_list[0][1]\n",
    "        return np.nan\n",
    "    \n",
    "    lo = LiftOver('hg19', 'hg38')\n",
    "    return [\n",
    "        convert(*x[1:]) for x in \n",
    "        df[['Chrom', 'Start', 'Strand']].itertuples()]\n",
    "\n",
    "def offset_starts(df, tot_offset=-1, neg_offset=-2):\n",
    "    \"\"\"\n",
    "    Offset start sites depending on a strand so they match our convention, \n",
    "    i.e., 0-based coordinates with \"Start\" pointing at the first nucleotide of a start codon.\n",
    "    The latter is inverted along with the sequence when the strand is negative, \n",
    "    e.g., CAT 1,2,3 -> ATG 3,2,1 => Start=3\n",
    "    \"\"\"\n",
    "    return [\n",
    "        (end + neg_offset if strand == '-' else start) + tot_offset \n",
    "        for _, start, end, strand in \n",
    "        df[['Start', 'End', 'Strand']].itertuples()]\n",
    "\n",
    "def lift_and_fetch(df, ref):\n",
    "    df = df.copy()\n",
    "    df['Start'] = lift_starts(df)\n",
    "    df = df[~df.Start.isna()]\n",
    "    df['Start'] = df['Start'].astype(int)\n",
    "    df['CodonFetched'] = fetch_codons(df, ref)\n",
    "    return df\n",
    "\n",
    "def parse_ji(path, ref):\n",
    "    df = pd.read_excel(\n",
    "        path, sheet_name='uORF', usecols=[0, 2, 3, 4, 5], \n",
    "        names=['Gene', 'Chrom', 'Strand', 'Start', 'End']\n",
    "    )\n",
    "    df = df[df.Chrom.apply(lambda x: '_' not in x)]\n",
    "    # Offset for the negative strand is -3, total offset is zero\n",
    "    df['Start'] = offset_starts(df, 0, -3)\n",
    "    df = lift_and_fetch(df, ref)\n",
    "    df = df.rename(columns={'CodonFetched': 'Codon'}).drop(columns='End')\n",
    "    df = filter_codons(df)\n",
    "    return df\n",
    "\n",
    "def parse_scholtz(path, ref):\n",
    "    df = pd.read_csv(\n",
    "        path, skiprows=1,\n",
    "        usecols=[2, 3, 4, 5, 7, 8],\n",
    "        names=['Chrom', 'Start', 'End', 'GeneID', 'Strand', 'Codon']\n",
    "    )\n",
    "    # Offset for the negative strand is -2, total offset is -1, no lifting is needed.\n",
    "    df['Start'] = offset_starts(df)\n",
    "    df['CodonFetched'] = fetch_codons(df, ref)\n",
    "    df = filter_codons(df)\n",
    "    df['GeneID'] = df['GeneID'].apply(lambda x: x.split('.')[0])\n",
    "    df = df.drop(columns='End')\n",
    "    return df\n",
    "\n",
    "def parse_gil(path, ref):\n",
    "    df = pd.read_excel(\n",
    "        path, sheet_name='Supplemental_Table_4', \n",
    "        usecols=[0, 2, 3, 4, 5, 6], skiprows=3,\n",
    "        names=['ID', 'Codon', 'Chrom', 'Strand', 'Start', 'End']\n",
    "    )\n",
    "    df['TranscriptID'] = df['ID'].apply(lambda x: x.split('.')[0])\n",
    "    df = df.drop(columns='ID')\n",
    "    idx = df.Strand == '-'\n",
    "    # For + strand, offset by -1, for - strand, offset by -3\n",
    "    df.loc[~idx, 'Start'] = df.loc[~idx, 'Start'] - 1\n",
    "    df.loc[idx, 'Start'] = df.loc[idx, 'Start'] - 3\n",
    "    # Lift coordinates and filter\n",
    "    df = lift_and_fetch(df, ref)\n",
    "    df = filter_codons(df)\n",
    "    df = df.drop(columns='End')\n",
    "    return df\n",
    "\n",
    "def parse_pred(path):\n",
    "    \"\"\"\n",
    "    Read the dataset with predictions and filter to Test and Val datasets.\n",
    "    \n",
    "    Offset start coordinates. \n",
    "    In our convention, we used 0-based coordinates with \n",
    "        \"Start\" pointing at the first nucleotide of a start codon.\n",
    "    The latter was inverted along with the sequence when the strand is negative, \n",
    "        e.g., CAT 1,2,3 -> ATG 3,2,1 => Start=3\n",
    "    Now, we offset (back) the start by -2 so that it always points \n",
    "        to the first nucleotide of the + strand (so Start=1 in the above example).\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(path).rename(columns={'SeqEnum': 'Start', 'Start': 'Codon'})\n",
    "    df = df[df.Dataset == 'Test']\n",
    "    idx = df.Strand == '-'\n",
    "    df.loc[idx, 'Start'] = df.loc[idx, 'Start'] - 2\n",
    "    return df\n",
    "\n",
    "def annotate_predictions(df):\n",
    "    df = df.copy()\n",
    "    df['PredictionType'] = 'TP'\n",
    "    df.loc[(df.y_true == 1) & (df.y_pred == 0), 'PredictionType'] = 'FN'\n",
    "    df.loc[(df.y_true == 0) & (df.y_pred == 1), 'PredictionType'] = 'FP'\n",
    "    df.loc[(df.y_true == 0) & (df.y_pred == 0), 'PredictionType'] = 'TN'\n",
    "    return df\n",
    "\n",
    "def calc_pred_scores(df):\n",
    "    y_pred = df['y_pred'].values\n",
    "    y_true = df['y_true'].values\n",
    "    fn, fp, tn, tp = map(\n",
    "        lambda x: len(df[df.PredictionType == x]), \n",
    "        ['FN', 'FP', 'TN', 'TP'])\n",
    "    return {\n",
    "        'f1': f1_score(y_true, y_pred, zero_division=0), \n",
    "        'prc': precision_score(y_true, y_pred, zero_division=0), \n",
    "        'rec': recall_score(y_true, y_pred, zero_division=0),\n",
    "        'bac': balanced_accuracy_score(y_true, y_pred),\n",
    "        # 'roc_auc': roc_auc_score(y_true, y_prob),\n",
    "        'FN': fn, 'FP': fp, 'TN': tn, 'TP': tp,\n",
    "    }\n",
    "\n",
    "def merge_and_score(\n",
    "    df_pred, df_comp, df_comp_name, \n",
    "    on=['Chrom', 'Strand', 'Start', 'Codon']\n",
    "):\n",
    "    df_comp = df_comp.copy()\n",
    "    df_pred = df_pred.copy()\n",
    "    df_comp['Dataset'] = df_comp_name\n",
    "    df = df_pred.merge(\n",
    "        df_comp, how='left', on=on, suffixes=['_pred', '_comp'])\n",
    "    print(f'Merged size: {len(df)}')\n",
    "    comp_codons = set(df_comp.Codon)\n",
    "    df = df[df.Codon.isin(comp_codons)]\n",
    "    print(f'Filtered to {comp_codons} start codons: {len(df)}')\n",
    "    df['y_pred'] = 1\n",
    "    df.loc[df.Dataset_comp.isna(), 'y_pred'] = 0\n",
    "    df = annotate_predictions(df)\n",
    "    df = df.drop_duplicates(['Chrom', 'Strand', 'Codon', 'Start'])\n",
    "    # idx_of_codons = ((codon, df.Codon == codon) for codon in comp_codons)\n",
    "    scores = {codon: calc_pred_scores(df[df.Codon == codon]) for codon in comp_codons}\n",
    "    return df, scores\n",
    "\n",
    "def unravel_scores(scores):\n",
    "    for ds_name, ds_vs in scores.items():\n",
    "        for codon_name, codon_scores in ds_vs.items():\n",
    "            for score_name, score_val in codon_scores.items():\n",
    "                yield ds_name, codon_name, score_name, score_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dba76676-6b3e-4a9f-95dd-42093ff3836c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = parse_pred(PRED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ae3d3d9a-4772-47e3-ab1e-ab7898307cd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2dcce742e1484371aec2cc24314c21bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching:   0%|          | 0/1933 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-matching codons: 0\n",
      "Invalid start codons: 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19f5ef195c994e798bf4dc6e698e271c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching:   0%|          | 0/188787 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-matching codons: 792\n",
      "Invalid start codons: 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20690c2831d74c76ad47ddcb51aabe02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching:   0%|          | 0/6614 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid start codons: 36\n"
     ]
    }
   ],
   "source": [
    "scholtz = parse_scholtz(SCHOLTZ, ref)\n",
    "gil = parse_gil(GIL, ref)\n",
    "ji = parse_ji(JI, ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "29745ec0-1a74-4fa7-b082-d7d4eb7afc1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged size: 30856\n",
      "Filtered to {'ATG'} start codons: 2116\n",
      "Merged size: 30960\n",
      "Filtered to {'GTG', 'ATC', 'ACG', 'CTG', 'ATT', 'TTG', 'ATG', 'ATA'} start codons: 22177\n",
      "Merged size: 30871\n",
      "Filtered to {'GTG', 'ATC', 'CTG', 'TTG', 'ATG'} start codons: 16936\n"
     ]
    }
   ],
   "source": [
    "ds_names = ['Scholtz', 'McGillivray', 'Ji']\n",
    "merged_dfs, scores = map(\n",
    "    list,\n",
    "    unzip(merge_and_score(pred, ds, ds_name) for ds, ds_name in \n",
    "     zip([scholtz, gil, ji], ds_names)))\n",
    "scores = {ds_name: s for ds_name, s in zip(ds_names, scores)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e2ad588d-56ad-4014-a98c-e22331d3224b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ScoreType</th>\n",
       "      <th>f1</th>\n",
       "      <th>prc</th>\n",
       "      <th>rec</th>\n",
       "      <th>bac</th>\n",
       "      <th>TN</th>\n",
       "      <th>FN</th>\n",
       "      <th>FP</th>\n",
       "      <th>TP</th>\n",
       "      <th>P</th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dataset</th>\n",
       "      <th>Codon</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">Ji</th>\n",
       "      <th>CTG</th>\n",
       "      <td>0.08</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.52</td>\n",
       "      <td>5653</td>\n",
       "      <td>185</td>\n",
       "      <td>22</td>\n",
       "      <td>9</td>\n",
       "      <td>194</td>\n",
       "      <td>5869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ATG</th>\n",
       "      <td>0.45</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.65</td>\n",
       "      <td>1931</td>\n",
       "      <td>116</td>\n",
       "      <td>15</td>\n",
       "      <td>54</td>\n",
       "      <td>170</td>\n",
       "      <td>2116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GTG</th>\n",
       "      <td>0.12</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.53</td>\n",
       "      <td>3787</td>\n",
       "      <td>79</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>85</td>\n",
       "      <td>3883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TTG</th>\n",
       "      <td>0.07</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.52</td>\n",
       "      <td>3050</td>\n",
       "      <td>42</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>44</td>\n",
       "      <td>3105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ATC</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1923</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>1948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"8\" valign=\"top\">McGillivray</th>\n",
       "      <th>CTG</th>\n",
       "      <td>0.17</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.68</td>\n",
       "      <td>4839</td>\n",
       "      <td>96</td>\n",
       "      <td>836</td>\n",
       "      <td>98</td>\n",
       "      <td>194</td>\n",
       "      <td>5869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ATG</th>\n",
       "      <td>0.37</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.68</td>\n",
       "      <td>1796</td>\n",
       "      <td>97</td>\n",
       "      <td>150</td>\n",
       "      <td>73</td>\n",
       "      <td>170</td>\n",
       "      <td>2116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GTG</th>\n",
       "      <td>0.12</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.68</td>\n",
       "      <td>3225</td>\n",
       "      <td>42</td>\n",
       "      <td>573</td>\n",
       "      <td>43</td>\n",
       "      <td>85</td>\n",
       "      <td>3883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACG</th>\n",
       "      <td>0.14</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.68</td>\n",
       "      <td>1150</td>\n",
       "      <td>20</td>\n",
       "      <td>267</td>\n",
       "      <td>24</td>\n",
       "      <td>44</td>\n",
       "      <td>1461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TTG</th>\n",
       "      <td>0.11</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.72</td>\n",
       "      <td>2654</td>\n",
       "      <td>19</td>\n",
       "      <td>407</td>\n",
       "      <td>25</td>\n",
       "      <td>44</td>\n",
       "      <td>3105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ATC</th>\n",
       "      <td>0.10</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.69</td>\n",
       "      <td>1713</td>\n",
       "      <td>13</td>\n",
       "      <td>210</td>\n",
       "      <td>12</td>\n",
       "      <td>25</td>\n",
       "      <td>1948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ATT</th>\n",
       "      <td>0.05</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.68</td>\n",
       "      <td>2113</td>\n",
       "      <td>8</td>\n",
       "      <td>248</td>\n",
       "      <td>7</td>\n",
       "      <td>15</td>\n",
       "      <td>2376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ATA</th>\n",
       "      <td>0.04</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.71</td>\n",
       "      <td>1206</td>\n",
       "      <td>2</td>\n",
       "      <td>105</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Scholtz</th>\n",
       "      <th>ATG</th>\n",
       "      <td>0.29</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.59</td>\n",
       "      <td>1937</td>\n",
       "      <td>140</td>\n",
       "      <td>9</td>\n",
       "      <td>30</td>\n",
       "      <td>170</td>\n",
       "      <td>2116</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "ScoreType            f1   prc   rec   bac    TN   FN   FP  TP    P  Total\n",
       "Dataset     Codon                                                        \n",
       "Ji          CTG    0.08  0.29  0.05  0.52  5653  185   22   9  194   5869\n",
       "            ATG    0.45  0.78  0.32  0.65  1931  116   15  54  170   2116\n",
       "            GTG    0.12  0.35  0.07  0.53  3787   79   11   6   85   3883\n",
       "            TTG    0.07  0.15  0.05  0.52  3050   42   11   2   44   3105\n",
       "            ATC    0.00  0.00  0.00  0.50  1923   25    0   0   25   1948\n",
       "McGillivray CTG    0.17  0.10  0.51  0.68  4839   96  836  98  194   5869\n",
       "            ATG    0.37  0.33  0.43  0.68  1796   97  150  73  170   2116\n",
       "            GTG    0.12  0.07  0.51  0.68  3225   42  573  43   85   3883\n",
       "            ACG    0.14  0.08  0.55  0.68  1150   20  267  24   44   1461\n",
       "            TTG    0.11  0.06  0.57  0.72  2654   19  407  25   44   3105\n",
       "            ATC    0.10  0.05  0.48  0.69  1713   13  210  12   25   1948\n",
       "            ATT    0.05  0.03  0.47  0.68  2113    8  248   7   15   2376\n",
       "            ATA    0.04  0.02  0.50  0.71  1206    2  105   2    4   1315\n",
       "Scholtz     ATG    0.29  0.77  0.18  0.59  1937  140    9  30  170   2116"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_scores = pd.DataFrame(\n",
    "    unravel_scores(scores), \n",
    "    columns=['Dataset', 'Codon', 'ScoreType', 'ScoreVal']\n",
    ").round(2).pivot(\n",
    "    index=['Dataset', 'Codon'], columns='ScoreType', values='ScoreVal'\n",
    ")\n",
    "\n",
    "for c in ['FN', 'FP', 'TN', 'TP']:\n",
    "    df_scores[c] = df_scores[c].astype(int)\n",
    "\n",
    "df_scores['P'] = df_scores['TP'] + df_scores['FN']\n",
    "df_scores['Total'] = (\n",
    "    df_scores['TP'] + df_scores['FN'] + df_scores['FP'] + df_scores['TN']\n",
    ")\n",
    "\n",
    "df_scores = df_scores.reset_index().sort_values(\n",
    "    ['Dataset', 'P'], ascending=[True, False]\n",
    ").set_index(['Dataset', 'Codon'])[[\n",
    "    'f1', 'prc', 'rec', 'bac', 'TN', 'FN', 'FP', 'TP', 'P', 'Total'\n",
    "]]\n",
    "\n",
    "df_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c8412cc9-61fe-4ba7-abe6-0b382b35f016",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrrrrrr}\n",
      "\\toprule\n",
      "ScoreType &    f1 &   prc &   rec &   bac &    TN &  FN &   FP &  TP \\\\\n",
      "Codon &       &       &       &       &       &     &      &     \\\\\n",
      "\\midrule\n",
      "CTG   &  0.17 &  0.10 &  0.51 &  0.68 &  4839 &  96 &  836 &  98 \\\\\n",
      "ATG   &  0.37 &  0.33 &  0.43 &  0.68 &  1796 &  97 &  150 &  73 \\\\\n",
      "GTG   &  0.12 &  0.07 &  0.51 &  0.68 &  3225 &  42 &  573 &  43 \\\\\n",
      "ACG   &  0.14 &  0.08 &  0.55 &  0.68 &  1150 &  20 &  267 &  24 \\\\\n",
      "TTG   &  0.11 &  0.06 &  0.57 &  0.72 &  2654 &  19 &  407 &  25 \\\\\n",
      "ATC   &  0.10 &  0.05 &  0.48 &  0.69 &  1713 &  13 &  210 &  12 \\\\\n",
      "ATT   &  0.05 &  0.03 &  0.47 &  0.68 &  2113 &   8 &  248 &   7 \\\\\n",
      "ATA   &  0.04 &  0.02 &  0.50 &  0.71 &  1206 &   2 &  105 &   2 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "\\begin{tabular}{lrrrrrrrr}\n",
      "\\toprule\n",
      "ScoreType &    f1 &   prc &   rec &   bac &    TN &   FN &  FP &  TP \\\\\n",
      "Codon &       &       &       &       &       &      &     &     \\\\\n",
      "\\midrule\n",
      "CTG   &  0.08 &  0.29 &  0.05 &  0.52 &  5653 &  185 &  22 &   9 \\\\\n",
      "ATG   &  0.45 &  0.78 &  0.32 &  0.65 &  1931 &  116 &  15 &  54 \\\\\n",
      "GTG   &  0.12 &  0.35 &  0.07 &  0.53 &  3787 &   79 &  11 &   6 \\\\\n",
      "TTG   &  0.07 &  0.15 &  0.05 &  0.52 &  3050 &   42 &  11 &   2 \\\\\n",
      "ATC   &  0.00 &  0.00 &  0.00 &  0.50 &  1923 &   25 &   0 &   0 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "\\begin{tabular}{lrrrrrrrr}\n",
      "\\toprule\n",
      "ScoreType &    f1 &   prc &   rec &   bac &    TN &   FN &  FP &  TP \\\\\n",
      "Codon &       &       &       &       &       &      &     &     \\\\\n",
      "\\midrule\n",
      "ATG   &  0.29 &  0.77 &  0.18 &  0.59 &  1937 &  140 &   9 &  30 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_22867/2451237430.py:3: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  print(df_scores.loc[n].drop(columns=['P', 'Total']).to_latex())\n",
      "/tmp/ipykernel_22867/2451237430.py:3: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  print(df_scores.loc[n].drop(columns=['P', 'Total']).to_latex())\n",
      "/tmp/ipykernel_22867/2451237430.py:3: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  print(df_scores.loc[n].drop(columns=['P', 'Total']).to_latex())\n"
     ]
    }
   ],
   "source": [
    "for n in ['McGillivray', 'Ji', 'Scholtz']:\n",
    "    \n",
    "    print(df_scores.loc[n].drop(columns=['P', 'Total']).to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "985305d4-358f-4725-9941-3b15f1348a53",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

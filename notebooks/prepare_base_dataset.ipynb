{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "# Base dataset preparation\n",
    "\n",
    "This notebook preparers the \"base\" dataset, i.e., a collection of properly annotated 5'UTRs.\n",
    "One can use this dataset with `uBERTa_loader` to prepare the training/validation/testing data for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from itertools import chain, starmap\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from more_itertools import sliding_window\n",
    "from toolz import curry\n",
    "from tqdm.auto import tqdm\n",
    "from uBERTa.base import VALID_START\n",
    "from uBERTa.utils import Ref, pBWs, reverse_complement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA = Path('../data')\n",
    "DATA.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "tags": []
   },
   "source": [
    "## Expected outputs\n",
    "- DS_BASE.tsv          -- base dataset with annotated 5'UTRs\n",
    "- dataset_labeling.tsv -- labeling of the analyzed genes as training, validation, and testing\n",
    "\n",
    "## Initial data\n",
    "\n",
    "This notebook requires:\n",
    "- hg38 reference genome\n",
    "- ribo-seq experimental signal from GWIPS-viz (we use P-site identification experiments only)\n",
    "- our hand-crafted dataset as a bed file\n",
    "- 5'UTR regions: provided with the rest of the data; also can be obtained via R package [ORFik](https://bioconductor.org/packages/release/bioc/html/ORFik.html) (see `extract_5UTR.rmd` notebook)\n",
    "- A mapping between Ensembl gene IDs and OMIM gene names\n",
    "- A list of analyzed genes\n",
    "\n",
    "Download the data and unpack it into the `DATA` dir initialized above.\n",
    "\n",
    "There are two archives you'll need:\n",
    "1. [prepare_base_dataset.zip](https://drive.google.com/file/d/1phgab69jDsvgMqOeGUp9mGdDDRU12pk_/view?usp=sharing) (riboseq data, 5'UTRs, etc.) \n",
    "2. [hg38.fa.tar.gz](https://drive.google.com/file/d/1obZdHGf06FFeGw7PCDh5gvMtRjHLKMHu/view?usp=sharing) (reference and its indexing in FASTA format)\n",
    "\n",
    "Download both of them and unpack into `DATA`. The expected structure of the `DATA` after this would be:\n",
    "\n",
    "```\n",
    "|____ENSG2OMIM.csv                                                                         \n",
    "|____List_of_analysed_unique_genes.csv\n",
    "|____hg38.fa\n",
    "|____hg38.fa.fai\n",
    "|____All_starts_AD+AR_v2.bed\n",
    "|____p-sites\n",
    "| |____Raj16_All.RiboProInit.bw\n",
    "| |____Fijalkowska17_All.RiboProInit.bw\n",
    "| |____Gao14_All.RiboProInit.bw\n",
    "| |____Ji15_All.RiboProInit.bw\n",
    "| |____Zhang17_All.RiboProInit.bw\n",
    "| |____Chen20_All.RiboProInit.bw\n",
    "| |____Gawron16_All.RiboProInit.bw\n",
    "| |____Crappe15_All.RiboProInit.bw\n",
    "|____uORF_search_space\n",
    "| |____uORF_search_space_cage_genes.gff\n",
    "| |____uORF_search_space_cage_transcripts.gff\n",
    "```\n",
    "\n",
    "For instance, starting from the project's root.\n",
    "\n",
    "1. Download the data\n",
    "\n",
    "```bash\n",
    "gdown --fuzzy https://drive.google.com/file/d/1obZdHGf06FFeGw7PCDh5gvMtRjHLKMHu/view?usp=sharing\n",
    "gdown --fuzzy https://drive.google.com/file/d/1phgab69jDsvgMqOeGUp9mGdDDRU12pk_/view?usp=sharing\n",
    "```\n",
    "\n",
    "2. Unpack downloads\n",
    "\n",
    "```bash\n",
    "unzip prepare_base_dataset.zip\n",
    "rm prepare_base_dataset.zip\n",
    "\n",
    "for path in $(ls *.tar.gz); do\n",
    "    tar -xzf $path\n",
    "done\n",
    "\n",
    "rm *.tar.gz\n",
    "\n",
    "ls\n",
    "```\n",
    "\n",
    "-> \n",
    "\n",
    "```bash\n",
    "All_starts_AD+AR_v2.bed  ENSG2OMIM.csv  hg38.fa  hg38.fa.fai  List_of_analysed_unique_genes.csv  p-sites  uORF_search_space\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference genome to fetch sequence regions\n",
    "ref = Ref(DATA / 'hg38.fa')\n",
    "# Experimental ribo-seq signal as a collection of BigWig files queried simultaneously\n",
    "pbws = pBWs(Path(DATA / 'p-sites').glob('*'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Parse the hand-crafted dataset\n",
    "\n",
    "- Convert the hand-crafted dataset into a dataframe\n",
    "- Validate annotation correctness\n",
    "- Fetch start codon sequences\n",
    "- Filter invalid start codons (should be removed in the final version, but exercising some caution never hurts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_hand_crafted(path):\n",
    "    \"\"\"\n",
    "    Convert a bed file with hand-crafted uORFs to a Pandas dataframe\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(\n",
    "        path, sep='\\s+', skiprows=1, skipfooter=1,\n",
    "        names=['Chrom', 'Start', 'End', 'Ann', 'X', 'Strand'])\n",
    "    valid_ann_idx = np.array(\n",
    "        [len(x.split('-')) == 5 for x in df['Ann']])\n",
    "    df_invalid = df[~valid_ann_idx]\n",
    "    df = df[valid_ann_idx]\n",
    "    df[['Group', 'Gene', 'StartCodon', 'KozakScore', 'Level']] = [\n",
    "        x.split('-') for x in df['Ann']]\n",
    "    return df, df_invalid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7312 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_24783/3068235612.py:5: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support skipfooter; you can avoid this warning by specifying engine='python'.\n",
      "  df = pd.read_csv(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Chrom</th>\n",
       "      <th>Start</th>\n",
       "      <th>End</th>\n",
       "      <th>Strand</th>\n",
       "      <th>Group</th>\n",
       "      <th>Gene</th>\n",
       "      <th>StartCodon</th>\n",
       "      <th>Level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5511</th>\n",
       "      <td>chrX</td>\n",
       "      <td>155264457</td>\n",
       "      <td>155264460</td>\n",
       "      <td>-</td>\n",
       "      <td>u</td>\n",
       "      <td>RAB39B</td>\n",
       "      <td>ATC</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7284</th>\n",
       "      <td>chrX</td>\n",
       "      <td>155264493</td>\n",
       "      <td>155264496</td>\n",
       "      <td>-</td>\n",
       "      <td>u</td>\n",
       "      <td>RAB39B</td>\n",
       "      <td>ATG</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7058</th>\n",
       "      <td>chrX</td>\n",
       "      <td>155545273</td>\n",
       "      <td>155545276</td>\n",
       "      <td>-</td>\n",
       "      <td>m</td>\n",
       "      <td>TMLHE</td>\n",
       "      <td>ATG</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5512</th>\n",
       "      <td>chrX</td>\n",
       "      <td>155612830</td>\n",
       "      <td>155612833</td>\n",
       "      <td>-</td>\n",
       "      <td>u</td>\n",
       "      <td>TMLHE</td>\n",
       "      <td>CTG</td>\n",
       "      <td>247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5513</th>\n",
       "      <td>chrX</td>\n",
       "      <td>155612861</td>\n",
       "      <td>155612864</td>\n",
       "      <td>-</td>\n",
       "      <td>u</td>\n",
       "      <td>TMLHE</td>\n",
       "      <td>CTG</td>\n",
       "      <td>127</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Chrom      Start        End Strand Group    Gene StartCodon Level\n",
       "5511  chrX  155264457  155264460      -     u  RAB39B        ATC    88\n",
       "7284  chrX  155264493  155264496      -     u  RAB39B        ATG   113\n",
       "7058  chrX  155545273  155545276      -     m   TMLHE        ATG     0\n",
       "5512  chrX  155612830  155612833      -     u   TMLHE        CTG   247\n",
       "5513  chrX  155612861  155612864      -     u   TMLHE        CTG   127"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds, ds_inv = parse_hand_crafted(\n",
    "    DATA / 'All_starts_AD+AR_v2.bed'\n",
    ")\n",
    "ds = ds.drop(\n",
    "    columns=['Ann', 'X', 'KozakScore']\n",
    ").sort_values(\n",
    "    ['Chrom', 'Start']\n",
    ")\n",
    "\n",
    "print(len(ds), len(ds_inv))\n",
    "ds.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c56a063f043f47a8801585722cb3ac05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7312 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ds['StartCodonFetched'] = [\n",
    "    ref.fetch(*x[1:]).upper() for x in\n",
    "    tqdm(ds[['Chrom', 'Start', 'End']].itertuples(), total=len(ds))]\n",
    "\n",
    "neg_idx = ds['Strand'] == '-'\n",
    "ds.loc[neg_idx, 'StartCodonFetched'] = ds.loc[\n",
    "    neg_idx, 'StartCodonFetched'].apply(reverse_complement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial 7312\n",
      "Matching start codons: 7303\n",
      "Supported start codons: 7296\n"
     ]
    }
   ],
   "source": [
    "print(f'Initial {len(ds)}')\n",
    "ds = ds[ds.StartCodon == ds.StartCodonFetched]\n",
    "print(f'Matching start codons: {len(ds)}')\n",
    "ds = ds.drop(columns=['StartCodonFetched'])\n",
    "ds = ds[ds.StartCodon.isin(VALID_START)]\n",
    "print(f'Supported start codons: {len(ds)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mapping gene names to ensemble IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "name2id = dict(\n",
    "    x[1:] for x in\n",
    "    pd.read_csv(DATA / 'ENSG2OMIM.csv', sep=';').itertuples())\n",
    "ds['GeneID'] = ds['Gene'].map(name2id.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final ds size: 7296\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Chrom</th>\n",
       "      <th>Start</th>\n",
       "      <th>End</th>\n",
       "      <th>Strand</th>\n",
       "      <th>Group</th>\n",
       "      <th>Gene</th>\n",
       "      <th>StartCodon</th>\n",
       "      <th>Level</th>\n",
       "      <th>GeneID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3028</th>\n",
       "      <td>chr1</td>\n",
       "      <td>1013523</td>\n",
       "      <td>1013526</td>\n",
       "      <td>+</td>\n",
       "      <td>u</td>\n",
       "      <td>ISG15</td>\n",
       "      <td>TTG</td>\n",
       "      <td>770</td>\n",
       "      <td>ENSG00000187608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5514</th>\n",
       "      <td>chr1</td>\n",
       "      <td>1013546</td>\n",
       "      <td>1013549</td>\n",
       "      <td>+</td>\n",
       "      <td>ma</td>\n",
       "      <td>ISG15</td>\n",
       "      <td>GTG</td>\n",
       "      <td>556</td>\n",
       "      <td>ENSG00000187608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6474</th>\n",
       "      <td>chr1</td>\n",
       "      <td>1013573</td>\n",
       "      <td>1013576</td>\n",
       "      <td>+</td>\n",
       "      <td>m</td>\n",
       "      <td>ISG15</td>\n",
       "      <td>ATG</td>\n",
       "      <td>0</td>\n",
       "      <td>ENSG00000187608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5920</th>\n",
       "      <td>chr1</td>\n",
       "      <td>1020172</td>\n",
       "      <td>1020175</td>\n",
       "      <td>+</td>\n",
       "      <td>m</td>\n",
       "      <td>AGRN</td>\n",
       "      <td>ATG</td>\n",
       "      <td>174</td>\n",
       "      <td>ENSG00000188157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2302</th>\n",
       "      <td>chr1</td>\n",
       "      <td>1349062</td>\n",
       "      <td>1349065</td>\n",
       "      <td>-</td>\n",
       "      <td>m</td>\n",
       "      <td>DVL1</td>\n",
       "      <td>ATG</td>\n",
       "      <td>379</td>\n",
       "      <td>ENSG00000107404</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Chrom    Start      End Strand Group   Gene StartCodon Level  \\\n",
       "3028  chr1  1013523  1013526      +     u  ISG15        TTG   770   \n",
       "5514  chr1  1013546  1013549      +    ma  ISG15        GTG   556   \n",
       "6474  chr1  1013573  1013576      +     m  ISG15        ATG     0   \n",
       "5920  chr1  1020172  1020175      +     m   AGRN        ATG   174   \n",
       "2302  chr1  1349062  1349065      -     m   DVL1        ATG   379   \n",
       "\n",
       "               GeneID  \n",
       "3028  ENSG00000187608  \n",
       "5514  ENSG00000187608  \n",
       "6474  ENSG00000187608  \n",
       "5920  ENSG00000188157  \n",
       "2302  ENSG00000107404  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f'Final ds size: {len(ds)}')\n",
    "ds.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse 5'UTR regions\n",
    "\n",
    "- Parse GFF files with 5'UTR coordinates obtained externally using ORFik\n",
    "- Fetch and enumerate sequences\n",
    "- Fetch experimental signal for 5'UTRs\n",
    "- Concatenate data transcript-wise\n",
    "- Handle strand direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_anno_value(field_name, anno):\n",
    "    _anno = dict(x.split('=') for x in anno.split(';'))\n",
    "    return _anno[field_name]\n",
    "\n",
    "def parse_granges_gff(path):\n",
    "    allowed_chr = list(map(str, range(1, 23))) + ['X', 'Y']\n",
    "\n",
    "    df_gff = pd.read_csv(\n",
    "        path, usecols=[0, 3, 4, 6, 8], sep=r'\\s+', low_memory=False,\n",
    "        names=['Chrom', 'Start', 'End', 'Strand', 'Anno'], skiprows=3)\n",
    "    print(f'Initial size: {len(df_gff)}')\n",
    "    df_gff = df_gff[df_gff.Anno.apply(lambda x: 'exon' in x)]\n",
    "    print(f'Filtered to exons: {len(df_gff)}')\n",
    "    df_gff = df_gff[df_gff.Chrom.isin(allowed_chr)]\n",
    "    print(f'Filtered to canonical chromosomes: {len(df_gff)}')\n",
    "    df_gff['Chrom'] = df_gff.Chrom.apply(lambda x: 'chr' + x)\n",
    "    df_gff['ExonID'] = df_gff.Anno.apply(lambda x: get_anno_value('exon_name', x))\n",
    "    df_gff['ID'] = df_gff.Anno.apply(lambda x: get_anno_value('Name', x))\n",
    "    df_gff = df_gff.drop(columns=['Anno'])\n",
    "    df_gff = df_gff.drop_duplicates(ignore_index=True)\n",
    "    print(f'Filtered out duplicates: {len(df_gff)}')\n",
    "    return df_gff\n",
    "\n",
    "@curry\n",
    "def join(it, sep=';'):\n",
    "    return sep.join(map(str, it))\n",
    "\n",
    "def safe_take_fst(vs):\n",
    "    if len(vs.unique()) != 1:\n",
    "        raise ValueError(vs)\n",
    "    return vs.iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two files parsed below encompass exactly the same 5'UTR regions, only the IDs attached to regions are on different level (genes and transcripts, respectively)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "genes_path = DATA / 'uORF_search_space' / 'uORF_search_space_cage_genes.gff'\n",
    "transcripts_path = DATA / 'uORF_search_space' / 'uORF_search_space_cage_transcripts.gff'\n",
    "assert genes_path.exists()\n",
    "assert transcripts_path.exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial size: 252701\n",
      "Filtered to exons: 163270\n",
      "Filtered to canonical chromosomes: 163233\n",
      "Filtered out duplicates: 112368\n",
      "Initial size: 252701\n",
      "Filtered to exons: 163270\n",
      "Filtered to canonical chromosomes: 163233\n",
      "Filtered out duplicates: 163233\n"
     ]
    }
   ],
   "source": [
    "df_genes = parse_granges_gff(\n",
    "    genes_path\n",
    ").rename(\n",
    "    columns={'ID': 'GeneID'}\n",
    ")\n",
    "df_trans = parse_granges_gff(\n",
    "    transcripts_path\n",
    ").rename(\n",
    "    columns={'ID': 'TranscriptID'}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "163233"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var = ['Chrom', 'Start', 'End', 'Strand']\n",
    "\n",
    "df_utr = pd.merge(\n",
    "    df_genes, df_trans, on=var +['ExonID']\n",
    ").sort_values(\n",
    "    var\n",
    ").reset_index(drop=True)\n",
    "df_utr['Start'] = df_utr['Start'] - 1\n",
    "len(df_utr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv('data/intermediate/5UTR_exons.tsv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parsed genomic ranges are continuous exonic regions within 5'UTR. We first compose sequence-level features for them, and then concatenate these features (sequences, enumeration, signal) for each transcript.\n",
    "\n",
    "Example (exons are already sorted by the starting coordinate in the ascending order):\n",
    "```\n",
    "ENST   ENSE  Seq  Enum    Signal\n",
    "100500 1     ACGT 1,2,3,4 0.1.0.0,0.1,20.0\n",
    "100500 2     CCGT 6,7,8,9 0.2.0.1,4.0,0.0\n",
    "```\n",
    "-->\n",
    "```\n",
    "ENST   Seq      Enum            Signal\n",
    "100500 ACGTCCGT 1,2,3,4,6,7,8,9 0.1.0.0,0.1,20.0,0.2.0.1,4.0,0.0\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "588a0a69284e4e7d9fe64271607b0927",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching seqs:   0%|          | 0/163233 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1179558b8974852ba8eb8e5de7e2988",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Enumerating seqs:   0%|          | 0/163233 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87f410e3a99f4913a28af143982219d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching signal:   0%|          | 0/163233 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_utr['Seq'] = [\n",
    "    ref.fetch(*x[1:]).upper() for x in \n",
    "    tqdm(df_utr[['Chrom', 'Start', 'End']].itertuples(), total=len(df_utr), desc='Fetching seqs')\n",
    "]\n",
    "df_utr['SeqEnum'] = [\n",
    "    join(range(row['Start'], row['End']), sep=',') for _, row in \n",
    "    tqdm(df_utr.iterrows(), total=len(df_utr), desc='Enumerating seqs')\n",
    "]\n",
    "df_utr['Signal'] = [\n",
    "    join(pbws.query(*x[1:]), sep=',') for x in \n",
    "    tqdm(df_utr[['Chrom', 'Start', 'End']].itertuples(), total=len(df_utr), desc='Fetching signal')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_utr = df_utr.groupby(\n",
    "    'TranscriptID', as_index=False\n",
    ").agg(\n",
    "    {'ExonID': join, \n",
    "     'GeneID': join, \n",
    "     'Seq': join(sep=''), \n",
    "     'SeqEnum': join(sep=','),\n",
    "     'Signal': join(sep=','),\n",
    "     'Chrom': safe_take_fst,\n",
    "     'Strand': safe_take_fst\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sanity check: all the concatenated sequences are of equal lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all(len(enum.split(',')) == len(signal.split(',')) == len(seq) \n",
    "    for _, seq, enum, signal in df_utr[['Seq', 'SeqEnum', 'Signal']].itertuples())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the distributions of (1) the number of exons per transcript, and (2) the 5'UTR exonic sequence's length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_join = lambda x: join(x.split(',')[::-1], sep=',')\n",
    "idx = df_utr.Strand == '-'\n",
    "df_utr.loc[idx, 'Seq'] = df_utr.loc[idx, 'Seq'].apply(reverse_complement)\n",
    "df_utr.loc[idx, 'SeqEnum'] = df_utr.loc[idx, 'SeqEnum'].apply(reverse_join)\n",
    "df_utr.loc[idx, 'Signal'] = df_utr.loc[idx, 'Signal'].apply(reverse_join)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TranscriptID</th>\n",
       "      <th>ExonID</th>\n",
       "      <th>GeneID</th>\n",
       "      <th>Seq</th>\n",
       "      <th>SeqEnum</th>\n",
       "      <th>Signal</th>\n",
       "      <th>Chrom</th>\n",
       "      <th>Strand</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ENST00000000233</td>\n",
       "      <td>ENSE00001872691</td>\n",
       "      <td>ENSG00000004059</td>\n",
       "      <td>CTGCTGCTGCTGCGCCCCATCCCCCCGCGGCCGGCCAGTTCCAGCC...</td>\n",
       "      <td>127588410,127588411,127588412,127588413,127588...</td>\n",
       "      <td>110.0,9.0,28.0,65.0,1.0,15.0,52.0,1.0,34.0,71....</td>\n",
       "      <td>chr7</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENST00000000412</td>\n",
       "      <td>ENSE00003523177;ENSE00001348389</td>\n",
       "      <td>ENSG00000003056;ENSG00000003056</td>\n",
       "      <td>AGAGTGGGGCACAGCGAGGCGCTAGGGGGAACGCTGGCCTCTGAAA...</td>\n",
       "      <td>8949644,8949643,8949642,8949641,8949640,894963...</td>\n",
       "      <td>2.0,19.0,68.0,143.0,14.0,7.0,3.0,1.0,1.0,4.0,0...</td>\n",
       "      <td>chr12</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ENST00000000442</td>\n",
       "      <td>ENSE00001884684;ENSE00001195360</td>\n",
       "      <td>ENSG00000173153;ENSG00000173153</td>\n",
       "      <td>GTCAGCTGGAGGAAGCGGAGTAGGAAGCGGCCGCGATGTCCTTTTG...</td>\n",
       "      <td>64305523,64305524,64305525,64305526,64305527,6...</td>\n",
       "      <td>0.0,0.0,1.0,4.0,3.0,0.0,1.0,1.0,1.0,9.0,0.0,4....</td>\n",
       "      <td>chr11</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ENST00000001008</td>\n",
       "      <td>ENSE00000802791</td>\n",
       "      <td>ENSG00000004478</td>\n",
       "      <td>CCTACCCCAGCTCTCGCGCCGCGTGCAGAGGTGCTCAAGCCTCCTC...</td>\n",
       "      <td>2794969,2794970,2794971,2794972,2794973,279497...</td>\n",
       "      <td>0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,3....</td>\n",
       "      <td>chr12</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENST00000001146</td>\n",
       "      <td>ENSE00000401861</td>\n",
       "      <td>ENSG00000003137</td>\n",
       "      <td>ACAGCCAATCCCCCGAGCGGCCGCCAAC</td>\n",
       "      <td>72147861,72147860,72147859,72147858,72147857,7...</td>\n",
       "      <td>0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0....</td>\n",
       "      <td>chr2</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      TranscriptID                           ExonID  \\\n",
       "0  ENST00000000233                  ENSE00001872691   \n",
       "1  ENST00000000412  ENSE00003523177;ENSE00001348389   \n",
       "2  ENST00000000442  ENSE00001884684;ENSE00001195360   \n",
       "3  ENST00000001008                  ENSE00000802791   \n",
       "4  ENST00000001146                  ENSE00000401861   \n",
       "\n",
       "                            GeneID  \\\n",
       "0                  ENSG00000004059   \n",
       "1  ENSG00000003056;ENSG00000003056   \n",
       "2  ENSG00000173153;ENSG00000173153   \n",
       "3                  ENSG00000004478   \n",
       "4                  ENSG00000003137   \n",
       "\n",
       "                                                 Seq  \\\n",
       "0  CTGCTGCTGCTGCGCCCCATCCCCCCGCGGCCGGCCAGTTCCAGCC...   \n",
       "1  AGAGTGGGGCACAGCGAGGCGCTAGGGGGAACGCTGGCCTCTGAAA...   \n",
       "2  GTCAGCTGGAGGAAGCGGAGTAGGAAGCGGCCGCGATGTCCTTTTG...   \n",
       "3  CCTACCCCAGCTCTCGCGCCGCGTGCAGAGGTGCTCAAGCCTCCTC...   \n",
       "4                       ACAGCCAATCCCCCGAGCGGCCGCCAAC   \n",
       "\n",
       "                                             SeqEnum  \\\n",
       "0  127588410,127588411,127588412,127588413,127588...   \n",
       "1  8949644,8949643,8949642,8949641,8949640,894963...   \n",
       "2  64305523,64305524,64305525,64305526,64305527,6...   \n",
       "3  2794969,2794970,2794971,2794972,2794973,279497...   \n",
       "4  72147861,72147860,72147859,72147858,72147857,7...   \n",
       "\n",
       "                                              Signal  Chrom Strand  \n",
       "0  110.0,9.0,28.0,65.0,1.0,15.0,52.0,1.0,34.0,71....   chr7      +  \n",
       "1  2.0,19.0,68.0,143.0,14.0,7.0,3.0,1.0,1.0,4.0,0...  chr12      -  \n",
       "2  0.0,0.0,1.0,4.0,3.0,0.0,1.0,1.0,1.0,9.0,0.0,4....  chr11      +  \n",
       "3  0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,3....  chr12      +  \n",
       "4  0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0....   chr2      -  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_utr.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Annotate 5'UTRs\n",
    "\n",
    "For the 5'UTRs, we assign classes to all supported start codons according to our hand-crafted dataset.\n",
    "Namely, for each codon, we place:\n",
    "- 1, if it is within our data\n",
    "- 0, if it is a valid start codon, but its absent in our data\n",
    "- 100 if none of the above is True (-100 is a default masking value for the loss functions in Pytorch)\n",
    "\n",
    "We then append (-100, -100) to classes of each sequence to account for kmerization. \n",
    "\n",
    "For example, in the sequence below, where ATG is absent in our data, and CTG is present, we'll compose the following sequence of classes:\n",
    "```\n",
    "ATGCTG -> ATG TGC GCT CTG -> 0 -100 -100 1 -100 -100\n",
    "```\n",
    "Hence, effectively we attribute a class to each character of a sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subset_to_positives(row, positives):\n",
    "    chrom, strand = row['Chrom'], row['Strand']\n",
    "    positives_enum = \",\".join(\n",
    "        x for x in row['SeqEnum'].split(',') \n",
    "        if (chrom, strand, int(x)) in positives)\n",
    "    return np.nan if not positives_enum else positives_enum\n",
    "\n",
    "def validate_codon(start, codon, seq, seq_enum):\n",
    "    \"\"\"Validate the codon sequence\"\"\"\n",
    "    idx_start = np.where(seq_enum == start)[0]\n",
    "    seq_codon = seq[idx_start:idx_start + 3]\n",
    "    return seq_codon == codon\n",
    "\n",
    "def classify_seq_codons(row):\n",
    "    def classify_codon(codon, pos):\n",
    "        if int(pos) in positives:\n",
    "            return 1\n",
    "        if codon in VALID_START:\n",
    "            return 0\n",
    "        return -100\n",
    "\n",
    "    kmers3 = map(lambda x: ''.join(x), sliding_window(row.Seq, 3))\n",
    "    enum = row.SeqEnum.split(',')\n",
    "    positives = row['SeqEnumPositive']\n",
    "    if not isinstance(positives, str):\n",
    "        positives = []\n",
    "    else:\n",
    "        positives = list(map(int, positives.split(',')))\n",
    "        # this accounts for the reversed sequences having \n",
    "        # a start codon coordinate at the end of an actual \n",
    "        # start codon given the correct direction\n",
    "        # e.g., for a \"-\" strand codon ATG with coordinates (3,2,1)\n",
    "        # our data will have coordinate \"1\" instead of \"3\" \n",
    "        # (and, for the \"+\" strand, vice versa). Here, we unify the classes' \n",
    "        # placement within a kmer sequence so that it's always assigned \n",
    "        # by the first nucleotide of a kmer \n",
    "        if row['Strand'] == '-':\n",
    "            positives = [x + 2 for x in positives]\n",
    "\n",
    "    labels = starmap(classify_codon, zip(kmers3, enum))\n",
    "\n",
    "    return ','.join(map(str, chain(labels, [-100, -100])))\n",
    "\n",
    "def safe_take_fst(vs):\n",
    "    vs = set(vs.split(';'))\n",
    "    assert len(vs) == 1\n",
    "    return vs.pop()\n",
    "\n",
    "def verify_codons(row):\n",
    "    classes = np.array(list(map(int, row['Classes'].split(','))))\n",
    "    m = classes != -100\n",
    "    starts = np.array(tuple(map(\n",
    "        lambda x: ''.join(x), sliding_window(row['Seq'], 3))) + ('PAD', 'PAD'))\n",
    "    return set(starts[m]).issubset(VALID_START)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compose the \"search space\" of positive classes. Hence, for a valid start codon to classify as positive, its coordinates (chrom, strand, start)  must by present in our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('chr1', '+', 1013523), ('chr1', '+', 1013546), ('chr1', '+', 1013573))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positives = tuple(x[1:] for x in ds[['Chrom', 'Strand', 'Start']].itertuples())\n",
    "positives[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merciless slow and painful yolo strategy... It however, ensures that we assign classes correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d7b151d7156468ca5989d2a9e5f5b90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Subsetting:   0%|          | 0/89404 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_utr['SeqEnumPositive'] = [\n",
    "    subset_to_positives(row, positives) for _, row in \n",
    "    tqdm(df_utr.iterrows(), total=len(df_utr), desc='Subsetting')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f17cf94499104b64b63d995d19660b28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Assigning classes:   0%|          | 0/89404 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_utr['Classes'] = [\n",
    "    classify_seq_codons(row) for _, row in \n",
    "    tqdm(df_utr.iterrows(), total=len(df_utr), desc='Assigning classes')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we verify the labeled start codons. Namely, we use the -100 values of the assigned classes as mask, and check that applying this mask results in subsetting the sequence to valid start codons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57929fb6e87f49bea1a9271c8414751f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/89404 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 problematic, 89404 OK\n"
     ]
    }
   ],
   "source": [
    "idx = np.array([verify_codons(row) for _, row in tqdm(df_utr.iterrows(), total=len(df_utr))])\n",
    "print(f'{(~idx).sum()} problematic, {idx.sum()} OK')\n",
    "df_utr = df_utr[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Frequently, different transcripts don't change the 5'UTR sequence. Below, we get rid of such duplicates by retaining only unique sequences. Thus, the retained sequences will be labeled by the first transcript ID in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial size: 89404\n",
      "Removed duplcates: 79677\n"
     ]
    }
   ],
   "source": [
    "print(f'Initial size: {len(df_utr)}')\n",
    "df_utr = df_utr.drop_duplicates('Seq')\n",
    "print(f'Removed duplcates: {len(df_utr)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'-100': 1967914, '0': 283973, '1': 19572})"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(chain.from_iterable(\n",
    "    df_utr.loc[\n",
    "        ~df_utr.SeqEnumPositive.isna(), 'Classes'\n",
    "    ].apply(\n",
    "        lambda x: x.split(','))\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is another sanity check which verifies that no transcript ID is associated with multiple gene IDs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_utr['GeneID'] = df_utr['GeneID'].apply(safe_take_fst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we assign boolean values to gene IDs that had been included into the manual curation process. The list of analyzed genes is an external resource. Additionally, since we already marked posititive examples via coordinates, we include the corresponding gene IDs to the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56 1731 3699\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False    60025\n",
       "True     19652\n",
       "Name: AnalyzedGene, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with (DATA / 'List_of_analysed_unique_genes.csv').open() as f:\n",
    "    gene_names = [l.rstrip() for l in f]\n",
    "    genes_curated = set(name2id[n] for n in gene_names if n in name2id)\n",
    "genes_ds = set(df_utr.loc[~df_utr['SeqEnumPositive'].isna(), 'GeneID'])\n",
    "analyzed_genes = genes_curated | genes_ds\n",
    "\n",
    "print(len(genes_ds - genes_curated), len(genes_curated - genes_ds), len(analyzed_genes))\n",
    "\n",
    "df_utr['AnalyzedGene'] = False\n",
    "df_utr.loc[df_utr['GeneID'].isin(analyzed_genes), 'AnalyzedGene'] = True\n",
    "df_utr['AnalyzedGene'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_utr.to_csv(DATA / 'DS_BASE.tsv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Divide the modeling dataset into training, validation, and testing\n",
    "\n",
    "The modeling dataset encompasses the sequences of analyzed genes. Here, we divide genes into training, validation, and testing subsets and label their sequences accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19652"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mod = df_utr[df_utr.AnalyzedGene].copy().reset_index(drop=True)\n",
    "len(df_mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Train    2948\n",
       "Test      368\n",
       "Val       368\n",
       "Name: Dataset, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(287)\n",
    "\n",
    "df_genes = pd.DataFrame({'GeneID': df_mod['GeneID'].unique()})\n",
    "val_frac, test_frac = 0.1, 0.1\n",
    "l = len(df_genes)\n",
    "n_test = int(l * val_frac)\n",
    "n_val = int(l * test_frac)\n",
    "n_train = l - n_test - n_val\n",
    "labels = np.concatenate(\n",
    "    [np.full(n_train, 'Train'), \n",
    "     np.full(n_val, 'Val'), \n",
    "     np.full(n_test, 'Test')])\n",
    "np.random.shuffle(labels)\n",
    "df_genes['Dataset'] = labels \n",
    "df_genes['Dataset'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_genes.to_csv(DATA / 'dataset_labeling.tsv', sep='\\t', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

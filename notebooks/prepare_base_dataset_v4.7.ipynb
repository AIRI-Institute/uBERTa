{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Base dataset preparation\n",
    "\n",
    "This notebook preparers the \"base\" dataset, i.e., a collection of properly annotated 5'UTRs.\n",
    "One can use this dataset with `uBERTa_loader` to prepare the training/validation/testing data for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from itertools import chain, starmap\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from more_itertools import sliding_window\n",
    "from toolz import curry\n",
    "from tqdm import tqdm\n",
    "from uBERTa.base import VALID_START\n",
    "from uBERTa.utils import Ref, pBWs, reverse_complement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(666)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA = Path('../data')\n",
    "DATA.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Expected outputs\n",
    "- DS_BASE_v4.7_seqs.tsv -- base dataset with annotated 5'UTRs with sequence-level features merged transcript-wise\n",
    "- dataset_labeling_v4.7.tsv -- labeling of the analyzed genes as training, validation, and testing\n",
    "\n",
    "## Initial data\n",
    "\n",
    "This notebook requires:\n",
    "- hg38 reference genome\n",
    "- ribo-seq experimental signal from GWIPS-viz (we use P-site identification experiments only)\n",
    "- our hand-crafted dataset as a bed file\n",
    "- 5'UTR regions: provided with the rest of the data; also can be obtained via R package [ORFik](https://bioconductor.org/packages/release/bioc/html/ORFik.html)\n",
    "- A mapping between Ensembl gene IDs and OMIM gene names\n",
    "- A list of analyzed genes\n",
    "\n",
    "Download the data and unpack it into the `DATA` dir initialized above.\n",
    "\n",
    "There are two archives you'll need:\n",
    "1. [prepare_base_dataset.zip](https://drive.google.com/file/d/1phgab69jDsvgMqOeGUp9mGdDDRU12pk_/view?usp=sharing) (riboseq data, 5'UTRs, etc.) \n",
    "2. [hg38.fa.tar.gz](https://drive.google.com/file/d/1obZdHGf06FFeGw7PCDh5gvMtRjHLKMHu/view?usp=sharing) (reference and its indexing in FASTA format)\n",
    "\n",
    "Download both of them and unpack into `DATA`. The expected structure of the `DATA` after this would be:\n",
    "\n",
    "```\n",
    "|____ENSG2OMIM.csv                                                                         \n",
    "|____List_of_analysed_unique_genes.csv\n",
    "|____hg38.fa\n",
    "|____hg38.fa.fai\n",
    "|____All_starts_AD+AR_v4.7.bed\n",
    "|____p-sites\n",
    "| |____Raj16_All.RiboProInit.bw\n",
    "| |____Fijalkowska17_All.RiboProInit.bw\n",
    "| |____Gao14_All.RiboProInit.bw\n",
    "| |____Ji15_All.RiboProInit.bw\n",
    "| |____Zhang17_All.RiboProInit.bw\n",
    "| |____Chen20_All.RiboProInit.bw\n",
    "| |____Gawron16_All.RiboProInit.bw\n",
    "| |____Crappe15_All.RiboProInit.bw\n",
    "|____uORF_search_space\n",
    "| |____uORF_search_space_cage_genes.gff\n",
    "| |____uORF_search_space_cage_transcripts.gff\n",
    "```\n",
    "\n",
    "For instance, starting from the project's root.\n",
    "\n",
    "1. Download the data\n",
    "\n",
    "```bash\n",
    "gdown --fuzzy https://drive.google.com/file/d/1obZdHGf06FFeGw7PCDh5gvMtRjHLKMHu/view?usp=sharing\n",
    "gdown --fuzzy https://drive.google.com/file/d/1phgab69jDsvgMqOeGUp9mGdDDRU12pk_/view?usp=sharing\n",
    "```\n",
    "\n",
    "2. Unpack downloads\n",
    "\n",
    "```bash\n",
    "unzip prepare_base_dataset.zip\n",
    "rm prepare_base_dataset.zip\n",
    "\n",
    "for path in $(ls *.tar.gz); do\n",
    "    tar -xzf $path\n",
    "done\n",
    "\n",
    "rm *.tar.gz\n",
    "\n",
    "ls\n",
    "```\n",
    "\n",
    "->\n",
    "\n",
    "```bash\n",
    "All_starts_AD+AR_v4.7.bed  ENSG2OMIM.csv  hg38.fa  hg38.fa.fai  List_of_analysed_unique_genes.csv  p-sites  uORF_search_space\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference genome to fetch sequence regions\n",
    "ref = Ref(DATA / 'hg38.fa')\n",
    "# Experimental ribo-seq signal as a collection of BigWig files queried simultaneously\n",
    "pbws = pBWs(Path(DATA / 'p-sites').glob('*'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Parse the hand-crafted dataset\n",
    "\n",
    "- Convert the hand-crafted dataset into a dataframe\n",
    "- Validate annotation correctness\n",
    "- Fetch start codon sequences\n",
    "- Filter invalid start codons (should be removed in the final version, but exercising some caution never hurts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_hand_crafted(path):\n",
    "    \"\"\"\n",
    "    Convert a bed file with hand-crafted uORFs to a Pandas dataframe\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(\n",
    "        path, sep='\\s+', skiprows=1, skipfooter=1,\n",
    "        names=['Chrom', 'Start', 'End', 'Ann', 'X', 'Strand'])\n",
    "    valid_ann_idx = np.array(\n",
    "        [len(x.split('-')) == 5 for x in df['Ann']])\n",
    "    df_invalid = df[~valid_ann_idx]\n",
    "    df = df[valid_ann_idx]\n",
    "    df[['Group', 'Gene', 'StartCodon', 'KozakScore', 'Level']] = [\n",
    "        x.split('-') for x in df['Ann']]\n",
    "    return df, df_invalid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7741 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_29310/3068235612.py:5: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support skipfooter; you can avoid this warning by specifying engine='python'.\n",
      "  df = pd.read_csv(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Chrom</th>\n",
       "      <th>Start</th>\n",
       "      <th>End</th>\n",
       "      <th>Strand</th>\n",
       "      <th>Group</th>\n",
       "      <th>Gene</th>\n",
       "      <th>StartCodon</th>\n",
       "      <th>Level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5398</th>\n",
       "      <td>chrX</td>\n",
       "      <td>155264457</td>\n",
       "      <td>155264460</td>\n",
       "      <td>-</td>\n",
       "      <td>u</td>\n",
       "      <td>RAB39B</td>\n",
       "      <td>ATC</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5400</th>\n",
       "      <td>chrX</td>\n",
       "      <td>155264493</td>\n",
       "      <td>155264496</td>\n",
       "      <td>-</td>\n",
       "      <td>u</td>\n",
       "      <td>RAB39B</td>\n",
       "      <td>ATG</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6802</th>\n",
       "      <td>chrX</td>\n",
       "      <td>155545273</td>\n",
       "      <td>155545276</td>\n",
       "      <td>-</td>\n",
       "      <td>m</td>\n",
       "      <td>TMLHE</td>\n",
       "      <td>ATG</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6800</th>\n",
       "      <td>chrX</td>\n",
       "      <td>155612830</td>\n",
       "      <td>155612833</td>\n",
       "      <td>-</td>\n",
       "      <td>u</td>\n",
       "      <td>TMLHE</td>\n",
       "      <td>CTG</td>\n",
       "      <td>247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6801</th>\n",
       "      <td>chrX</td>\n",
       "      <td>155612861</td>\n",
       "      <td>155612864</td>\n",
       "      <td>-</td>\n",
       "      <td>u</td>\n",
       "      <td>TMLHE</td>\n",
       "      <td>CTG</td>\n",
       "      <td>127</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Chrom      Start        End Strand Group    Gene StartCodon Level\n",
       "5398  chrX  155264457  155264460      -     u  RAB39B        ATC    88\n",
       "5400  chrX  155264493  155264496      -     u  RAB39B        ATG   113\n",
       "6802  chrX  155545273  155545276      -     m   TMLHE        ATG     0\n",
       "6800  chrX  155612830  155612833      -     u   TMLHE        CTG   247\n",
       "6801  chrX  155612861  155612864      -     u   TMLHE        CTG   127"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds, ds_inv = parse_hand_crafted(\n",
    "    DATA / 'All_starts_AD+AR_v4.7.bed'\n",
    ")\n",
    "ds = ds.drop(\n",
    "    columns=['Ann', 'X', 'KozakScore']\n",
    ").sort_values(\n",
    "    ['Chrom', 'Start']\n",
    ")\n",
    "\n",
    "print(len(ds), len(ds_inv))\n",
    "ds.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 7741/7741 [00:00<00:00, 215928.62it/s]\n"
     ]
    }
   ],
   "source": [
    "ds['StartCodonFetched'] = [\n",
    "    ref.fetch(*x[1:]).upper() for x in\n",
    "    tqdm(ds[['Chrom', 'Start', 'End']].itertuples(), total=len(ds))]\n",
    "\n",
    "neg_idx = ds['Strand'] == '-'\n",
    "ds.loc[neg_idx, 'StartCodonFetched'] = ds.loc[\n",
    "    neg_idx, 'StartCodonFetched'].apply(reverse_complement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial 7741\n",
      "Matching start codons: 7725\n",
      "Supported start codons: 7719\n"
     ]
    }
   ],
   "source": [
    "print(f'Initial {len(ds)}')\n",
    "ds = ds[ds.StartCodon == ds.StartCodonFetched]\n",
    "print(f'Matching start codons: {len(ds)}')\n",
    "ds = ds.drop(columns=['StartCodonFetched'])\n",
    "ds = ds[ds.StartCodon.isin(VALID_START)]\n",
    "print(f'Supported start codons: {len(ds)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mapping gene names to ensemble IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "name2id = dict(\n",
    "    x[1:] for x in\n",
    "    pd.read_csv(DATA / 'ENSG2OMIM.csv', sep=';').itertuples())\n",
    "ds['GeneID'] = ds['Gene'].map(name2id.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final ds size: 7719\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Chrom</th>\n",
       "      <th>Start</th>\n",
       "      <th>End</th>\n",
       "      <th>Strand</th>\n",
       "      <th>Group</th>\n",
       "      <th>Gene</th>\n",
       "      <th>StartCodon</th>\n",
       "      <th>Level</th>\n",
       "      <th>GeneID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3336</th>\n",
       "      <td>chr1</td>\n",
       "      <td>1013523</td>\n",
       "      <td>1013526</td>\n",
       "      <td>+</td>\n",
       "      <td>u</td>\n",
       "      <td>ISG15</td>\n",
       "      <td>TTG</td>\n",
       "      <td>770</td>\n",
       "      <td>ENSG00000187608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3337</th>\n",
       "      <td>chr1</td>\n",
       "      <td>1013546</td>\n",
       "      <td>1013549</td>\n",
       "      <td>+</td>\n",
       "      <td>ma</td>\n",
       "      <td>ISG15</td>\n",
       "      <td>GTG</td>\n",
       "      <td>556</td>\n",
       "      <td>ENSG00000187608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3338</th>\n",
       "      <td>chr1</td>\n",
       "      <td>1013573</td>\n",
       "      <td>1013576</td>\n",
       "      <td>+</td>\n",
       "      <td>m</td>\n",
       "      <td>ISG15</td>\n",
       "      <td>ATG</td>\n",
       "      <td>0</td>\n",
       "      <td>ENSG00000187608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>chr1</td>\n",
       "      <td>1020172</td>\n",
       "      <td>1020175</td>\n",
       "      <td>+</td>\n",
       "      <td>m</td>\n",
       "      <td>AGRN</td>\n",
       "      <td>ATG</td>\n",
       "      <td>174</td>\n",
       "      <td>ENSG00000188157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990</th>\n",
       "      <td>chr1</td>\n",
       "      <td>1349062</td>\n",
       "      <td>1349065</td>\n",
       "      <td>-</td>\n",
       "      <td>m</td>\n",
       "      <td>DVL1</td>\n",
       "      <td>ATG</td>\n",
       "      <td>379</td>\n",
       "      <td>ENSG00000107404</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Chrom    Start      End Strand Group   Gene StartCodon Level  \\\n",
       "3336  chr1  1013523  1013526      +     u  ISG15        TTG   770   \n",
       "3337  chr1  1013546  1013549      +    ma  ISG15        GTG   556   \n",
       "3338  chr1  1013573  1013576      +     m  ISG15        ATG     0   \n",
       "224   chr1  1020172  1020175      +     m   AGRN        ATG   174   \n",
       "1990  chr1  1349062  1349065      -     m   DVL1        ATG   379   \n",
       "\n",
       "               GeneID  \n",
       "3336  ENSG00000187608  \n",
       "3337  ENSG00000187608  \n",
       "3338  ENSG00000187608  \n",
       "224   ENSG00000188157  \n",
       "1990  ENSG00000107404  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f'Final ds size: {len(ds)}')\n",
    "ds.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse 5'UTR regions\n",
    "\n",
    "- Parse GFF files with 5'UTR coordinates obtained externally using ORFik\n",
    "- Fetch and enumerate sequences\n",
    "- Fetch experimental signal for 5'UTRs\n",
    "- Concatenate data transcript-wise\n",
    "- Handle strand direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_anno_value(field_name, anno):\n",
    "    _anno = dict(x.split('=') for x in anno.split(';'))\n",
    "    return _anno[field_name]\n",
    "\n",
    "def parse_granges_gff(path):\n",
    "    allowed_chr = list(map(str, range(1, 23))) + ['X', 'Y']\n",
    "\n",
    "    df_gff = pd.read_csv(\n",
    "        path, usecols=[0, 3, 4, 6, 8], sep=r'\\s+', low_memory=False,\n",
    "        names=['Chrom', 'Start', 'End', 'Strand', 'Anno'], skiprows=3)\n",
    "    print(f'Initial size: {len(df_gff)}')\n",
    "    df_gff = df_gff[df_gff.Anno.apply(lambda x: 'exon' in x)]\n",
    "    print(f'Filtered to exons: {len(df_gff)}')\n",
    "    df_gff = df_gff[df_gff.Chrom.isin(allowed_chr)]\n",
    "    print(f'Filtered to canonical chromosomes: {len(df_gff)}')\n",
    "    df_gff['Chrom'] = df_gff.Chrom.apply(lambda x: 'chr' + x)\n",
    "    df_gff['ExonID'] = df_gff.Anno.apply(lambda x: get_anno_value('exon_name', x))\n",
    "    df_gff['ID'] = df_gff.Anno.apply(lambda x: get_anno_value('Name', x))\n",
    "    df_gff = df_gff.drop(columns=['Anno'])\n",
    "    df_gff = df_gff.drop_duplicates(ignore_index=True)\n",
    "    print(f'Filtered out duplicates: {len(df_gff)}')\n",
    "    return df_gff\n",
    "\n",
    "@curry\n",
    "def join(it, sep=';'):\n",
    "    return sep.join(map(str, it))\n",
    "\n",
    "def safe_take_fst(vs):\n",
    "    if len(vs.unique()) != 1:\n",
    "        raise ValueError(vs)\n",
    "    return vs.iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two files parsed below encompass exactly the same 5'UTR regions, only the IDs attached to regions are on different level (genes and transcripts, respectively)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "genes_path = DATA / 'uORF_search_space' / 'uORF_search_space_cage_genes.gff'\n",
    "transcripts_path = DATA / 'uORF_search_space' / 'uORF_search_space_cage_transcripts.gff'\n",
    "assert genes_path.exists()\n",
    "assert transcripts_path.exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial size: 252701\n",
      "Filtered to exons: 163270\n",
      "Filtered to canonical chromosomes: 163233\n",
      "Filtered out duplicates: 112368\n",
      "Initial size: 252701\n",
      "Filtered to exons: 163270\n",
      "Filtered to canonical chromosomes: 163233\n",
      "Filtered out duplicates: 163233\n"
     ]
    }
   ],
   "source": [
    "df_genes = parse_granges_gff(\n",
    "    genes_path\n",
    ").rename(\n",
    "    columns={'ID': 'GeneID'}\n",
    ")\n",
    "df_trans = parse_granges_gff(\n",
    "    transcripts_path\n",
    ").rename(\n",
    "    columns={'ID': 'TranscriptID'}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "163233"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var = ['Chrom', 'Start', 'End', 'Strand']\n",
    "\n",
    "df_utr = pd.merge(\n",
    "    df_genes, df_trans, on=var + ['ExonID']\n",
    ").sort_values(\n",
    "    var\n",
    ").reset_index(drop=True)\n",
    "df_utr['Start'] = df_utr['Start'] - 1\n",
    "len(df_utr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv('data/intermediate/5UTR_exons.tsv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parsed genomic ranges are continuous exonic regions within 5'UTR. We first compose sequence-level features for them, and then concatenate these features (sequences, enumeration, signal) for each transcript.\n",
    "\n",
    "Example (exons are already sorted by the starting coordinate in the ascending order):\n",
    "```\n",
    "ENST   ENSE  Seq  Enum    Signal\n",
    "100500 1     ACGT 1,2,3,4 0.1.0.0,0.1,20.0\n",
    "100500 2     CCGT 6,7,8,9 0.2.0.1,4.0,0.0\n",
    "```\n",
    "-->\n",
    "```\n",
    "ENST   Seq      Enum            Signal\n",
    "100500 ACGTCCGT 1,2,3,4,6,7,8,9 0.1.0.0,0.1,20.0,0.2.0.1,4.0,0.0\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching seqs: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 163233/163233 [00:00<00:00, 320805.13it/s]\n",
      "Enumerating seqs: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 163233/163233 [00:07<00:00, 21522.80it/s]\n",
      "Fetching signal: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 163233/163233 [01:47<00:00, 1520.43it/s]\n"
     ]
    }
   ],
   "source": [
    "df_utr['Seq'] = [\n",
    "    ref.fetch(*x[1:]).upper() for x in \n",
    "    tqdm(df_utr[['Chrom', 'Start', 'End']].itertuples(), total=len(df_utr), desc='Fetching seqs')\n",
    "]\n",
    "df_utr['SeqEnum'] = [\n",
    "    join(range(row['Start'], row['End']), sep=',') for _, row in \n",
    "    tqdm(df_utr.iterrows(), total=len(df_utr), desc='Enumerating seqs')\n",
    "]\n",
    "df_utr['Signal'] = [\n",
    "    join(pbws.query(*x[1:]), sep=',') for x in \n",
    "    tqdm(df_utr[['Chrom', 'Start', 'End']].itertuples(), total=len(df_utr), desc='Fetching signal')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_utr = df_utr.groupby(\n",
    "    'TranscriptID', as_index=False\n",
    ").agg(\n",
    "    {'ExonID': join, \n",
    "     'GeneID': safe_take_fst, \n",
    "     'Seq': join(sep=''), \n",
    "     'SeqEnum': join(sep=','),\n",
    "     'Signal': join(sep=','),\n",
    "     'Chrom': safe_take_fst,\n",
    "     'Strand': safe_take_fst\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "- Remove anomalously short sequences right away"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "89404"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_utr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_utr = df_utr[df_utr.Seq.apply(lambda x: len(x) > 5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88507"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_utr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sanity check: all the concatenated sequences are of equal lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all(len(enum.split(',')) == len(signal.split(',')) == len(seq) \n",
    "    for seq, enum, signal in df_utr[\n",
    "        ['Seq', 'SeqEnum', 'Signal']].itertuples(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Handle direction:\n",
    "- For sequences: take the reverse complement\n",
    "- For signal and enumeration: reverse and join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_join = lambda x: join(x.split(',')[::-1], sep=',')\n",
    "idx = df_utr.Strand == '-'\n",
    "df_utr.loc[idx, 'Seq'] = df_utr.loc[idx, 'Seq'].apply(reverse_complement)\n",
    "df_utr.loc[idx, 'SeqEnum'] = df_utr.loc[idx, 'SeqEnum'].apply(reverse_join)\n",
    "df_utr.loc[idx, 'Signal'] = df_utr.loc[idx, 'Signal'].apply(reverse_join)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Kmerize sequences for overlapping with the hand-crafted dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kmers = df_utr[['TranscriptID', 'GeneID', 'Seq', 'SeqEnum', 'Signal', 'Chrom', 'Strand']].copy()\n",
    "df_kmers['Seq'] = df_kmers['Seq'].apply(\n",
    "    lambda x: [''.join(y) for y in sliding_window(x + 'XX', 3)])\n",
    "df_kmers['SeqEnum'] = df_kmers['SeqEnum'].apply(lambda x: x.split(','))\n",
    "df_kmers['Signal'] = df_kmers['Signal'].apply(lambda x: x.split(','))\n",
    "df_kmers = df_kmers.explode(['SeqEnum', 'Seq', 'Signal']).dropna()\n",
    "df_kmers['SeqEnum'] = df_kmers['SeqEnum'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kmers = df_kmers.rename(columns={'Seq': 'StartCodon'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "- Account for position shift for the reversed sequences\n",
    "- Merge with the hand-crafted dataset on genomic positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kmers['SeqEnumShift'] = df_kmers['SeqEnum'].copy()\n",
    "idx = df_kmers.Strand == '-'\n",
    "df_kmers.loc[idx, 'SeqEnumShift'] = df_kmers.loc[idx, 'SeqEnumShift'] - 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kmers = df_kmers.merge(\n",
    "    ds[['StartCodon', 'Start', 'Chrom', 'Strand']], \n",
    "    left_on=['SeqEnumShift', 'Chrom', 'Strand'], \n",
    "    right_on=['Start', 'Chrom', 'Strand'],\n",
    "    suffixes=['_transcript', '_curated'],\n",
    "    how='left'\n",
    ").drop(columns='Start')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "- This shows mismatching start-codons likely changed due to alternative splicing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TranscriptID</th>\n",
       "      <th>GeneID</th>\n",
       "      <th>StartCodon_transcript</th>\n",
       "      <th>SeqEnum</th>\n",
       "      <th>Signal</th>\n",
       "      <th>Chrom</th>\n",
       "      <th>Strand</th>\n",
       "      <th>SeqEnumShift</th>\n",
       "      <th>StartCodon_curated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12442888</th>\n",
       "      <td>ENST00000532463</td>\n",
       "      <td>ENSG00000198561</td>\n",
       "      <td>ATA</td>\n",
       "      <td>57762066</td>\n",
       "      <td>52.0</td>\n",
       "      <td>chr11</td>\n",
       "      <td>+</td>\n",
       "      <td>57762066</td>\n",
       "      <td>ATG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13056604</th>\n",
       "      <td>ENST00000540610</td>\n",
       "      <td>ENSG00000159403</td>\n",
       "      <td>ATA</td>\n",
       "      <td>7092387</td>\n",
       "      <td>0.0</td>\n",
       "      <td>chr12</td>\n",
       "      <td>-</td>\n",
       "      <td>7092385</td>\n",
       "      <td>ATG</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             TranscriptID           GeneID StartCodon_transcript   SeqEnum  \\\n",
       "12442888  ENST00000532463  ENSG00000198561                   ATA  57762066   \n",
       "13056604  ENST00000540610  ENSG00000159403                   ATA   7092387   \n",
       "\n",
       "         Signal  Chrom Strand  SeqEnumShift StartCodon_curated  \n",
       "12442888   52.0  chr11      +      57762066                ATG  \n",
       "13056604    0.0  chr12      -       7092385                ATG  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_kmers[(df_kmers.StartCodon_curated != df_kmers.StartCodon_transcript) & \n",
    "         ~df_kmers.StartCodon_curated.isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20579712"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_kmers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20579712"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_kmers = df_kmers.drop_duplicates()\n",
    "len(df_kmers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TranscriptID</th>\n",
       "      <th>GeneID</th>\n",
       "      <th>StartCodon_transcript</th>\n",
       "      <th>SeqEnum</th>\n",
       "      <th>Signal</th>\n",
       "      <th>Chrom</th>\n",
       "      <th>Strand</th>\n",
       "      <th>SeqEnumShift</th>\n",
       "      <th>StartCodon_curated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ENST00000000233</td>\n",
       "      <td>ENSG00000004059</td>\n",
       "      <td>CTG</td>\n",
       "      <td>127588410</td>\n",
       "      <td>110.0</td>\n",
       "      <td>chr7</td>\n",
       "      <td>+</td>\n",
       "      <td>127588410</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENST00000000233</td>\n",
       "      <td>ENSG00000004059</td>\n",
       "      <td>TGC</td>\n",
       "      <td>127588411</td>\n",
       "      <td>9.0</td>\n",
       "      <td>chr7</td>\n",
       "      <td>+</td>\n",
       "      <td>127588411</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ENST00000000233</td>\n",
       "      <td>ENSG00000004059</td>\n",
       "      <td>GCT</td>\n",
       "      <td>127588412</td>\n",
       "      <td>28.0</td>\n",
       "      <td>chr7</td>\n",
       "      <td>+</td>\n",
       "      <td>127588412</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ENST00000000233</td>\n",
       "      <td>ENSG00000004059</td>\n",
       "      <td>CTG</td>\n",
       "      <td>127588413</td>\n",
       "      <td>65.0</td>\n",
       "      <td>chr7</td>\n",
       "      <td>+</td>\n",
       "      <td>127588413</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENST00000000233</td>\n",
       "      <td>ENSG00000004059</td>\n",
       "      <td>TGC</td>\n",
       "      <td>127588414</td>\n",
       "      <td>1.0</td>\n",
       "      <td>chr7</td>\n",
       "      <td>+</td>\n",
       "      <td>127588414</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      TranscriptID           GeneID StartCodon_transcript    SeqEnum Signal  \\\n",
       "0  ENST00000000233  ENSG00000004059                   CTG  127588410  110.0   \n",
       "1  ENST00000000233  ENSG00000004059                   TGC  127588411    9.0   \n",
       "2  ENST00000000233  ENSG00000004059                   GCT  127588412   28.0   \n",
       "3  ENST00000000233  ENSG00000004059                   CTG  127588413   65.0   \n",
       "4  ENST00000000233  ENSG00000004059                   TGC  127588414    1.0   \n",
       "\n",
       "  Chrom Strand  SeqEnumShift StartCodon_curated  \n",
       "0  chr7      +     127588410                NaN  \n",
       "1  chr7      +     127588411                NaN  \n",
       "2  chr7      +     127588412                NaN  \n",
       "3  chr7      +     127588413                NaN  \n",
       "4  chr7      +     127588414                NaN  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_kmers.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Annotate 5'UTRs\n",
    "\n",
    "For the 5'UTRs, we assign classes to all supported start codons according to our hand-crafted dataset.\n",
    "Namely, for each codon, we place:\n",
    "- `1`, if it is within our data\n",
    "- `0`, if it is a valid start codon, but its absent in our data\n",
    "- `-100` if none of the above is True (`-100` is a default masking value for the loss functions in PyTorch)\n",
    "\n",
    "We then append `(-100, -100)` to the `Classes` field of each sequence to account for kmerization.\n",
    "\n",
    "For example, in the sequence below, where ATG is absent in our data, and CTG is present, we'll compose the following sequence of classes:\n",
    "```\n",
    "ATGCTG -> ATG TGC GCT CTG -> 0 -100 -100 1 -100 -100\n",
    "```\n",
    "Hence, effectively we attribute a class to each character of a sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_classes(df):\n",
    "    def classify_codon(codon_transcript, codon_curated):\n",
    "        if isinstance(codon_curated, str):\n",
    "            return '1'\n",
    "        if codon_transcript in VALID_START:\n",
    "            return '0'\n",
    "        return '-100'\n",
    "    \n",
    "    classes = ','.join(\n",
    "        classify_codon(x, y) for x, y in \n",
    "        df[['StartCodon_transcript', 'StartCodon_curated']].itertuples(index=False))\n",
    "    \n",
    "    return pd.Series({'Classes': classes})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "- We group k-merized sequences transcript-wise and aggregate (join) sequence data and associated genes.\n",
    "- Then we create classes for the same groups and add them to the aggregated dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = df_kmers.groupby(\n",
    "    ['Chrom', 'Strand', 'TranscriptID'], \n",
    "    as_index=False\n",
    ")\n",
    "df_seqs = groups.agg(\n",
    "    GeneID=pd.NamedAgg('GeneID', lambda x: x.iloc[0]),\n",
    "    SeqEnum=pd.NamedAgg('SeqEnum', join(sep=',')),\n",
    "    Signal=pd.NamedAgg('Signal', join(sep=',')),\n",
    "    Seq=pd.NamedAgg('StartCodon_transcript', lambda vs: ''.join(x[0] for x in vs)),\n",
    ")\n",
    "df_seqs['Classes'] = groups.apply(make_classes)['Classes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88507"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_seqs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Validate and save\n",
    "\n",
    "- Below, we'll verify the labeled start codons. Namely, we use the -100 values of the assigned classes as mask, and check that applying this mask results in subsetting the sequence to valid start codons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def validate_codon(start, codon, seq, seq_enum):\n",
    "#     \"\"\"Validate the codon sequence\"\"\"\n",
    "#     idx_start = np.where(seq_enum == start)[0]\n",
    "#     seq_codon = seq[idx_start:idx_start + 3]\n",
    "#     return seq_codon == codon\n",
    "\n",
    "STARTS = np.array(VALID_START)\n",
    "\n",
    "def verify_codons(row):\n",
    "    classes = np.array(list(map(int, row['Classes'].split(','))))\n",
    "    m = classes != -100\n",
    "    starts = np.array(tuple(map(\n",
    "        lambda x: ''.join(x), sliding_window(row['Seq'], 3))) + ('PAD', 'PAD'))\n",
    "    try:\n",
    "        codons = starts[m]\n",
    "        mask = np.isin(codons, STARTS)\n",
    "        invalid = codons[~mask]\n",
    "        has_invalid = len(invalid) > 0\n",
    "        if has_invalid:\n",
    "            print(\n",
    "                f'Invalid start codons {invalid} at positions {np.where(m)[0][~mask]} '\n",
    "                f'of transcript {row.TranscriptID}')\n",
    "        return not has_invalid\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TranscriptID</th>\n",
       "      <th>GeneID</th>\n",
       "      <th>StartCodon_transcript</th>\n",
       "      <th>SeqEnum</th>\n",
       "      <th>Signal</th>\n",
       "      <th>Chrom</th>\n",
       "      <th>Strand</th>\n",
       "      <th>SeqEnumShift</th>\n",
       "      <th>StartCodon_curated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [TranscriptID, GeneID, StartCodon_transcript, SeqEnum, Signal, Chrom, Strand, SeqEnumShift, StartCodon_curated]\n",
       "Index: []"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_kmers[~df_kmers.StartCodon_transcript.isin(VALID_START) & ~df_kmers.StartCodon_curated.isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 problematic, 88507 OK\n"
     ]
    }
   ],
   "source": [
    "idx = np.array([verify_codons(row) for _, row in df_seqs.iterrows()])\n",
    "print(f'{(~idx).sum()} problematic, {idx.sum()} OK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_seqs = df_seqs[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Frequently, different transcripts don't change the 5'UTR sequence. Below, we get rid of such duplicates by retaining only unique sequences. Thus, the retained sequences will be labeled by the first transcript ID in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial size: 88507\n",
      "Removed duplcates: 79453\n"
     ]
    }
   ],
   "source": [
    "print(f'Initial size: {len(df_seqs)}')\n",
    "df_seqs = df_seqs.drop_duplicates(['Seq', 'Signal'])\n",
    "print(f'Removed duplcates: {len(df_seqs)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_seqs.to_csv(DATA / 'DS_BASE_v4.7_seqs.tsv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kmers.to_csv(DATA / 'DS_BASE_v4.7_kmers.tsv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Partition the modeling dataset into training, validation, and testing\n",
    "\n",
    "- The modeling dataset encompasses the sequences of analyzed genes. Here, we divide genes into training, validation, and testing subsets and label their sequences accordingly.\n",
    "\n",
    "Certain analyzed genes overlap with other genes outside of the composed list. As we want to prevent including the same position into the training and validation/testing subsets, we need to handle such cases explicitly. For this, we'll group k-merized sequences by the genomic position and aggregate genes into overlapping groups. Then we'll distribute the groups between train/test/validation subsets. This ad-hoc solution handles only genes overlapping over sequences that were analyzed manually. However, if an analyzed gene X overlaps some gene Y, and the latter overlaps some gene Z that doesn't overlap X, gene Z won't be considered \"analyzed\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Genes in the supplied list:  3644\n"
     ]
    }
   ],
   "source": [
    "df_analyzed = pd.read_csv(DATA / 'List_of_analysed_unique_genes.csv', names=['GeneName'])\n",
    "df_analyzed['GeneID'] = df_analyzed['GeneName'].map(name2id)\n",
    "df_analyzed['Analyzed'] = True\n",
    "genes_curated = set(df_analyzed.GeneID)\n",
    "print('Genes in the supplied list: ', len(genes_curated))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_genes = pd.merge(\n",
    "    df_kmers[['GeneID', 'Chrom', 'Strand', 'SeqEnum', 'StartCodon_curated']], \n",
    "    df_analyzed[['GeneID', 'Analyzed']], \n",
    "    on=['GeneID'], how='left',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_genes.loc[~df_genes.StartCodon_curated.isna(), 'Analyzed'] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_genes = df_genes.groupby(\n",
    "    ['Chrom', 'Strand', 'SeqEnum'], as_index=False\n",
    ").agg({'Analyzed': 'any', 'GeneID': list})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Factual analyzed genes:  3761\n"
     ]
    }
   ],
   "source": [
    "genes_factual = set(chain.from_iterable(df_genes.loc[df_genes.Analyzed, 'GeneID']))\n",
    "print('Factual analyzed genes: ', len(genes_factual))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3757"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyzed_gene_groups = list(df_genes.loc[\n",
    "    df_genes.Analyzed, 'GeneID'\n",
    "].apply(lambda x: ';'.join(sorted(set(x)))).unique())\n",
    "len(analyzed_gene_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total overlapping genes groups:  123\n",
      "Total overlapping genes:  249\n",
      "Total non-overlapping gene groups:  3640\n"
     ]
    }
   ],
   "source": [
    "grouped_entries = [x for x in analyzed_gene_groups if ';' in x]\n",
    "print('Total overlapping genes groups: ', len(grouped_entries))\n",
    "overlapping = list(chain.from_iterable(x.split(';') for x in grouped_entries))\n",
    "print('Total overlapping genes: ', len(overlapping))\n",
    "non_overlapping = [x for x in analyzed_gene_groups if x not in overlapping]\n",
    "print('Total non-overlapping gene groups: ', len(non_overlapping))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3761\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Train    3011\n",
       "Test      379\n",
       "Val       371\n",
       "Name: Dataset, dtype: int64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_genes = pd.DataFrame({'GeneID': non_overlapping})\n",
    "\n",
    "val_frac, test_frac = 0.1, 0.1\n",
    "l = len(df_genes)\n",
    "n_test = int(l * val_frac)\n",
    "n_val = int(l * test_frac)\n",
    "n_train = l - n_test - n_val\n",
    "labels = np.concatenate(\n",
    "    [np.full(n_train, 'Train'), \n",
    "     np.full(n_val, 'Val'), \n",
    "     np.full(n_test, 'Test')])\n",
    "np.random.shuffle(labels)\n",
    "df_genes['Dataset'] = labels\n",
    "df_genes['GeneID'] = df_genes['GeneID'].apply(lambda x: x.split(';'))\n",
    "df_genes = df_genes.explode('GeneID').drop_duplicates('GeneID')\n",
    "print(len(df_genes))\n",
    "df_genes['Dataset'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_genes.to_csv(DATA / 'dataset_labeling_v4.7.tsv', sep='\\t', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "76153679-83ac-4e64-91df-3c9556f3d6a7",
   "metadata": {},
   "source": [
    "# Predict 5'UTR TISs\n",
    "\n",
    "Here, we'll use the fine-tuned `uBERTa_classifier` to predict TISs in 5'UTR sequences of the protein-coding genes of the human genome."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ec1264-7204-4904-9b1f-960b90e76e7b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Prerequisites\n",
    "\n",
    "This notebook requires:\n",
    "- [DS_BASE.tsv](https://drive.google.com/file/d/1gPjOoxWOAPpfPmKFbQlVT0hncjIpst5E/view?usp=sharing) (`../data/DS_BASE.tsv`)\n",
    "- [dataset_labeling.tsv](https://drive.google.com/file/d/1z_dQtERIPvf_ZqnGLCNGLx_l6GcKHJZ1/view?usp=sharing) (`../data/dataset_labeling.tsv`)\n",
    "- [trained_model](https://drive.google.com/file/d/1YAiyZXNzu49GoLaLEw4ocKX_45dRwC3e/view?usp=sharing) (`../models/ws100_step25_ACG_ATC_ATG_ATT_CTG_GTG_pretrain_tokenlevel_signal`)\n",
    "\n",
    "One can either download or obtain the requirements manually: `prepare_base_dataset.ipynb` for the first two, and `train_uBERTa.ipynb` for the fine-tuned model.\n",
    "\n",
    "For instance, starting from the project's root:\n",
    "```bash\n",
    "gdown --fuzzy https://drive.google.com/file/d/1gPjOoxWOAPpfPmKFbQlVT0hncjIpst5E/view?usp=sharing\n",
    "gdown --fuzzy https://drive.google.com/file/d/1z_dQtERIPvf_ZqnGLCNGLx_l6GcKHJZ1/view?usp=sharing\n",
    "tar -xzf DS_BASE.tsv.tar.gz\n",
    "tar -xzf dataset_labeling.tsv.tar.gz\n",
    "mkdir -p ../models\n",
    "cd ../models\n",
    "gdown --fuzzy https://drive.google.com/file/d/1YAiyZXNzu49GoLaLEw4ocKX_45dRwC3e/view?usp=sharing\n",
    "tar -xzf ws100_step25_ACG_ATC_ATG_ATT_CTG_GTG_pretrain_tokenlevel_signal.tar.gz\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b1b7602-f1a3-4027-a176-21d7cbeb93bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import operator as op\n",
    "from itertools import chain\n",
    "from math import ceil\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pytorch_lightning as pl\n",
    "from more_itertools import sliced\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.metrics import f1_score, recall_score, precision_score, roc_auc_score\n",
    "from torch.utils.data import DataLoader, SequentialSampler, TensorDataset\n",
    "from tqdm.auto import tqdm\n",
    "from transformers import DistilBertConfig\n",
    "\n",
    "from uBERTa.loader import uBERTaLoader\n",
    "from uBERTa.model import uBERTa_classifier, WeightedDistilBertClassifier\n",
    "from uBERTa.tokenizer import DNATokenizer\n",
    "from uBERTa.utils import split_values, kmerize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "042258da-4eb4-4c3d-afdf-1600003ee8c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_SEQ_SIZE = 10\n",
    "WINDOW = 100\n",
    "STEP = WINDOW // 4\n",
    "BASE = Path('../data')\n",
    "BASE.mkdir(exist_ok=True)\n",
    "MODEL_PATH = Path('../models/ws100_step25_ACG_ATC_ATG_ATT_CTG_GTG_pretrain_tokenlevel_signal/')\n",
    "DS = BASE / 'DS_BASE.tsv'\n",
    "DS_LABELS = BASE / 'dataset_labeling.tsv'\n",
    "STARTS = ('ACG', 'ATC', 'ATG', 'ATT', 'CTG', 'GTG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e265e04a-e7af-4429-bfeb-39cc966ac1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fa6175c1-de8e-434d-83e0-cc9648894ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_base(path_base, path_labels, min_seq_size):\n",
    "    \"\"\"\n",
    "    Read base dataset, merge gene labels (splitting genes into Train, \n",
    "        Test, and Valiation) and filter by seq size\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(path_base, sep='\\t')\n",
    "    df['SeqSize'] = df['Seq'].apply(len)\n",
    "    print(f'Initial ds: {len(df)}')\n",
    "    df_labels = pd.read_csv(path_labels, sep='\\t')\n",
    "    df = df.merge(df_labels, on='GeneID', how='left')\n",
    "    df = df[df.SeqSize >= min_seq_size]\n",
    "    print(f'Conforming to size threshold: {len(df)}')\n",
    "    split_values(df, 'SeqEnum')\n",
    "    split_values(df, 'SeqEnumPositive')\n",
    "    split_values(df, 'Classes')\n",
    "    split_values(df, 'Signal', dtype=float)\n",
    "    return df\n",
    "\n",
    "def aggregate_predictions(predictions):\n",
    "    \"\"\"\n",
    "    Detach and concatenate raw batch predictions\n",
    "    \"\"\"\n",
    "    y_prob = [x[1].detach().cpu().numpy() for x in predictions]\n",
    "    y_true = [x[2].detach().cpu().numpy() for x in predictions]\n",
    "    \n",
    "    return np.concatenate(y_prob), np.concatenate(y_true)\n",
    "\n",
    "def safe_take_fst(xs):\n",
    "    assert len(xs.unique()) == 1\n",
    "    return xs.iloc[0]\n",
    "\n",
    "def take_fst(xs):\n",
    "    return xs.iloc[0]\n",
    "\n",
    "def unravel_base_ds(path, keep_cols=('GeneID', 'TranscriptID')):\n",
    "    \"\"\"\n",
    "    Unravel sequence data of the base dataset into the codon-per-row format.\n",
    "    \"\"\"\n",
    "    \n",
    "    def unravel_row(row):\n",
    "        keep_values = [row[col] for col in keep_cols]\n",
    "        for i, (codon, en, cls) in enumerate(\n",
    "            zip(row.Seq.split(), row.SeqEnum, row.Classes)\n",
    "        ):\n",
    "            if cls != -100:\n",
    "                yield (row.Chrom, row.Strand, en, codon, *keep_values)\n",
    "    \n",
    "    df = pd.read_csv(path, sep='\\t')\n",
    "    split_values(df, 'SeqEnum')\n",
    "    df['Seq'] = df['Seq'].apply(lambda s: kmerize(s, 3))\n",
    "    unraveled = chain.from_iterable(\n",
    "        map(unravel_row, map(op.itemgetter(1), df.iterrows())))\n",
    "    # print(next(unraveled))\n",
    "\n",
    "    return pd.DataFrame(\n",
    "        unraveled,\n",
    "        columns=['Chrom', 'Strand', 'Start', 'Codon'] + list(keep_cols))\n",
    "\n",
    "def unravel_and_group(df, y_prob, y_true, threshold=0.5, pred_agg='mean'):\n",
    "    \"\"\"\n",
    "    Unravel sequences in the dataset to restructure as codon-per-row.\n",
    "    Aggregate predictions for the same codon.\n",
    "    \"\"\"\n",
    "    def unravel_row(row):\n",
    "        for i, (codon, en, cls, sig) in enumerate(\n",
    "            zip(row.Seq.split(), row.SeqEnum, row.Classes, row.Signal)\n",
    "        ):\n",
    "            if cls != -100:\n",
    "                yield row.Chrom, row.Strand, en, codon, cls, sig, row.Dataset\n",
    "    \n",
    "    # Unravel the dataset with predictions\n",
    "    unraveled = map(unravel_row, map(op.itemgetter(1), df.iterrows()))\n",
    "    _df = pd.DataFrame(\n",
    "        chain.from_iterable(unraveled), \n",
    "        columns=['Chrom', 'Strand', 'Start', 'Codon', \n",
    "                 'Label', 'Signal', 'Dataset'])\n",
    "    \n",
    "    # This serves as additional sanity check\n",
    "    # working iff the number of codons match\n",
    "    _df['y_prob'] = np.squeeze(y_prob[:, 1])  # Take the probability of the positive class\n",
    "    _df['y_true'] = np.squeeze(y_true)\n",
    "    \n",
    "    _df = _df[_df.Start != 0]\n",
    "    \n",
    "    # Average the predictions for each start codon across transcripts and windows\n",
    "    _df = _df.groupby(\n",
    "        ['Chrom', 'Strand', 'Start', 'Codon'], \n",
    "        as_index=False\n",
    "    ).agg({\n",
    "        'y_prob': pred_agg, \n",
    "        'y_true': safe_take_fst,\n",
    "        'Signal': take_fst,\n",
    "        'Dataset': take_fst,\n",
    "    })\n",
    "    \n",
    "    _df['y_pred'] = (_df['y_prob'] > threshold).astype(int)\n",
    "    \n",
    "    return _df\n",
    "\n",
    "def calc_pred_scores(df, threshold=0.5):\n",
    "    y_prob = df['y_prob'].values\n",
    "    y_pred = (df['y_prob'].values > threshold).astype(int)\n",
    "    y_true = df['y_true'].values\n",
    "    return {\n",
    "        'f1': f1_score(y_true, y_pred), \n",
    "        'prc': precision_score(y_true, y_pred), \n",
    "        'rec': recall_score(y_true, y_pred),\n",
    "        'roc_auc': roc_auc_score(y_true, y_prob)}\n",
    "\n",
    "def score(df, threshold):\n",
    "    scores = {\n",
    "        codon: calc_pred_scores(group, threshold) \n",
    "        for codon, group in df.groupby('Codon')}\n",
    "    scores['All'] = calc_pred_scores(df, threshold)\n",
    "    return scores\n",
    "\n",
    "def split_into_loaders(tds, chunk_size, batch_size = 2 ** 8):\n",
    "    for tensors in sliced(tds, chunk_size):\n",
    "        _tds = TensorDataset(*tensors)\n",
    "        yield DataLoader(\n",
    "            _tds, \n",
    "            sampler=SequentialSampler(_tds), \n",
    "            batch_size=2**7,\n",
    "            num_workers=4)\n",
    "        \n",
    "def split_df(df, chunk_size):\n",
    "    n = ceil(len(df) // chunk_size)\n",
    "    for i in range(n):\n",
    "        yield df.iloc[i * chunk_size: (i + 1) * chunk_size]\n",
    "\n",
    "def predict(loader, ds, model, trainer, threshold, agg_fn):\n",
    "    predictions = trainer.predict(model, loader)\n",
    "    y_prob, y_true = aggregate_predictions(predictions)\n",
    "    df = unravel_and_group(ds, y_prob, y_true, threshold, agg_fn)\n",
    "    return df\n",
    "\n",
    "def unravel_scores(scores):\n",
    "    for ds_name, ds_vs in scores.items():\n",
    "        for codon_name, codon_scores in ds_vs.items():\n",
    "            for score_name, score_val in codon_scores.items():\n",
    "                yield ds_name, codon_name, score_name, score_val\n",
    "                \n",
    "def get_color(y_pred, y_true, dataset):\n",
    "    green, blue, red, black = (\n",
    "        '0,255,0', '0,0,255', '255,0,0', '0,0,0')\n",
    "    if dataset == 'Inference':\n",
    "        if y_pred == 1:\n",
    "            return green\n",
    "        return blue\n",
    "    if y_pred == 1 and y_true == 1:\n",
    "        return green\n",
    "    if y_pred == 0 and y_true == 0:\n",
    "        return blue\n",
    "    if y_pred == 0 and y_true == 1:\n",
    "        return red\n",
    "    return black\n",
    "\n",
    "def wrap_row(row, ts=0.5):\n",
    "    label = row.Dataset\n",
    "    y_pred = int(row.y_prob >= 0.5)\n",
    "    color = get_color(y_pred, row.y_true, row.Dataset)\n",
    "    start = row.Start if row.Strand == '+' else row.Start - 2\n",
    "    end = start + 3\n",
    "    return (f'{row.Chrom} {start} {end} {label} '\n",
    "            f'{int(row.y_prob * 1000)} {row.Strand} {start} {end} {color}')\n",
    "\n",
    "def pred2bed(df, out_path):\n",
    "    with open(out_path, 'w') as f:\n",
    "        print('track name=\"uBERTa predictions v.1\" '\n",
    "              'itemRgb=\"On\"', file=f)\n",
    "        for _, row in tqdm(df.iterrows()):\n",
    "            print(wrap_row(row), file=f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a19bf875-4aef-4a9f-9d1d-9855be773680",
   "metadata": {},
   "source": [
    "## Prepare data\n",
    "\n",
    "We'll initalize `uBERTaLoader` without base dataset and use its methods to prepare the sequence data for predictions. This will take care of encoding inputs and sliding the window over the sequence data. Be careful to use the same setup as in `train_uBERTa.ipynb`, especially wrt window parameters and experimental signal bounds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "718dea0b-e1be-43c7-b940-f13303650dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = DNATokenizer(kmer=3)\n",
    "loader = uBERTaLoader(\n",
    "    None, WINDOW, STEP, tokenizer, \n",
    "    scale_signal_bounds=(0.0, 10.0),\n",
    "    is_mlm_task=False,\n",
    "    valid_start_codons=STARTS,\n",
    "    batch_size=2 ** 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7fa02af3-4b1e-48d8-8f18-1e4af1f0d677",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial ds: 79677\n",
      "Conforming to size threshold: 78702\n"
     ]
    }
   ],
   "source": [
    "ds = parse_base(DS, DS_LABELS, MIN_SEQ_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fef3df01-cb98-4efa-8195-9ece8e85e14e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:uBERTa.loader:Preparing Main with 78702 records for token-level task\n",
      "INFO:uBERTa.loader:Using kmer 3 on ('Seq', 'SeqEnum', 'Signal', 'Classes')\n",
      "DEBUG:uBERTa.loader:Reducing kmers for Main\n",
      "/home/ivan/miniconda3/envs/uberta/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3162: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return asarray(a).ndim\n",
      "DEBUG:uBERTa.loader:Filtering to ('ACG', 'ATC', 'ATG', 'ATT', 'CTG', 'GTG') for Main\n",
      "DEBUG:uBERTa.loader:Capping and scaling signal for Main\n",
      "DEBUG:uBERTa.loader:Capped signal in (0.1, 5000.0)\n",
      "DEBUG:uBERTa.loader:Scaled signal between 0 and 1. Min 0.1, Max 5000.0\n",
      "INFO:uBERTa.loader:Rolling window with size 98, step 25\n",
      "WARNING:uBERTa.loader:Removing 3052 out of 594202 windows without classes from Main. Consider calibrating window parameters.\n"
     ]
    }
   ],
   "source": [
    "ds = loader._prep_token_level(ds, 'Main')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "25da0424-b919-4699-9d3b-7579ea3f254d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tds = loader._prep_tds_cls(ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6675681-c3a7-4871-9c28-b823e9abfec2",
   "metadata": {},
   "source": [
    "Wrap the tensor dataset into `DataLoader`. Adjust the batch size and the number of processes as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f10da35c-c862-49a1-83cd-2974d9d085fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_loader = DataLoader(\n",
    "    tds, \n",
    "    sampler=SequentialSampler(tds), \n",
    "    batch_size=2**7,\n",
    "    num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f53131d-d3f0-4016-b770-83b69766344c",
   "metadata": {},
   "source": [
    "`idsmap`, obtained below, associates gene and transcript IDs with all putative TISs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a5f5be5b-929e-4f82-bb17-203630495b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "idsmap = unravel_base_ds(DS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c7fb6dd-f3e0-4897-ad12-e5ba25063f4b",
   "metadata": {},
   "source": [
    "## Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2c96641b-9ac2-4cc4-a940-859e1dcf8ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = DistilBertConfig.from_pretrained(MODEL_PATH)\n",
    "model = uBERTa_classifier(\n",
    "    model=WeightedDistilBertClassifier,\n",
    "    config=config,\n",
    ")\n",
    "model.model = model.model.from_pretrained(MODEL_PATH)\n",
    "model.model.config.use_signal = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e93cf1ec-502b-4750-b824-e43cfe82d48f",
   "metadata": {},
   "source": [
    "## Predict\n",
    "\n",
    "In some cases, using the whole dataset may overflow RAM, hence we'll split loaders into sizeable chunks and use them with the `Trainer` API in `predict` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ba746f19-7f3e-4423-a4bd-3e9bc0102359",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit native Automatic Mixed Precision (AMP)\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n"
     ]
    }
   ],
   "source": [
    "gpus = [1]\n",
    "trainer = pl.Trainer(\n",
    "    accelerator=\"gpu\",\n",
    "    precision=16,\n",
    "    gpus=gpus,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7697c9d0-165f-4929-9601-524fe15691e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_size = 20000\n",
    "loaders = split_into_loaders(tds, chunk_size)\n",
    "dss = split_df(ds, chunk_size)\n",
    "\n",
    "dfs = (predict(l, d, model, trainer, 0.5, 'mean') for l, d in zip(loaders, dss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "913bf3b3-61d5-42f8-8b69-fb5bd585e731",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "Missing logger folder: /home/ivan/code/uBERTa/notebooks/lightning_logs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d65fe76e92e4449bda06ff9a3617ada",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b27d041649f4ee0ad897530ee3d5f43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c22a53d8907548d49f873acc81ad3f0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c7de129afad4ac19d31c05dfa5f9cb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3718cdc0f1914397b90959c728588e52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5fdd8da75e744079da83fa64f1ef969",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98990e662fa2430a896c26a6e7368963",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "339f2ff348ed4486852ff3512ae29e91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "025a89c9cce64a30820db0d6fef5b482",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4b0db6677e449a5a581efbbb37bc756",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2683504ea4394efd9f453023638f0a12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40a32a1974694c1c94e32347bce099d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e712a443e9bc41708e3707e60af7c683",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7604ff40b1747a5855d0d145e34d36b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8efd8a74e6d54495ab36d829da0bf858",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7dcc6e36e2e845b180a4ef41207026ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ef9317c9b9f4e7597cf2d795b7ca2bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24a31ef38cf0427aa9f09f61582a54f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6f278d87b424796b354685aa5e2052c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "354045cbcef440e7ac8bfc441017f0b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3140a17c7ade453398aa46b76d64f4df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38e224a0a51a4814b59f2f89cb339602",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7036a10f67db4a40a1d21438aacfe5ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2be36a33dd644e4ac88d4db0430ea0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5cfc4508f88415ba3717268c6ffb13a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "755a2f36ea7d4158bed0b1c8f65b9a63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e970067f0a6d4ee5a339426835a91b13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a447be24d2de4a21a24ef5270c2e0c8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bf1f07131754190951319d8d287db61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_pred = pd.concat(dfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aecf5b6f-1dec-4835-b7d8-07cbdf074a53",
   "metadata": {},
   "source": [
    "## Parse and dump results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52078602-0c2b-4893-9073-9a81c994cda6",
   "metadata": {},
   "source": [
    "Explicitly mark the dataset for data not present in the modeling dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "90f9d75f-7ebc-4d88-958e-361c067f1917",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred.loc[df_pred.Dataset.isna(), 'Dataset'] = 'Inference'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f9105cb-d8bc-4d0f-919a-c4f13963805b",
   "metadata": {},
   "source": [
    "Due to splitting loader into chunks, we'll aggregate the probabilities the second time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7cda95dc-2e18-46ff-a92b-fb148c030cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred = df_pred.groupby(\n",
    "        ['Chrom', 'Strand', 'Start', 'Codon'], \n",
    "        as_index=False\n",
    "    ).agg({\n",
    "        'y_prob': 'mean',\n",
    "        'y_true': safe_take_fst,\n",
    "        'Signal': take_fst,\n",
    "        'Dataset': take_fst,\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ce78b2-d44b-4ad8-9c2e-5ce280d14ffb",
   "metadata": {},
   "source": [
    "Finally, we'll incorporate gene and transcript IDs for each start codon. If a TIS is associated with multiple transcripts, they'll be concatenated with \";\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5d61f926-885d-4905-a8d6-2877801432d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred = df_pred.merge(\n",
    "    idsmap, \n",
    "    on=['Chrom', 'Strand', 'Start', 'Codon'], \n",
    "    how='left'\n",
    ").groupby(\n",
    "    ['Chrom', 'Strand', 'Start', 'Codon'], as_index=False\n",
    ").agg({\n",
    "    'y_prob': take_fst, \n",
    "    'y_true': take_fst, \n",
    "    'Signal': take_fst, \n",
    "    'Dataset': take_fst,\n",
    "    'GeneID': take_fst,\n",
    "    'TranscriptID': lambda vs: ';'.join(vs)\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f0c5f1f-99f7-4790-a24f-f6d7bea28bd0",
   "metadata": {},
   "source": [
    "Score predictions separately for each part of the modeling dataset. The scores may be slightly different compared to the paper due to different seed used in splitting the modeling dataset in `prepare_base_dataset.ipynb` (the part of creating the `dataset_labeling.tsv`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "21771568-5acf-49b2-9c74-11967570aa43",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = {ds_name: score(df_pred[df_pred.Dataset == ds_name], 0.5) for ds_name in ('Train', 'Val', 'Test')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b955ba19-a7f3-4bbd-a048-cbdad95f4bd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Train': {'ACG': {'f1': 0.6203208556149733,\n",
       "   'prc': 0.6397058823529411,\n",
       "   'rec': 0.6020761245674741,\n",
       "   'roc_auc': 0.9867718790285803},\n",
       "  'ATC': {'f1': 0.5767790262172285,\n",
       "   'prc': 0.6062992125984252,\n",
       "   'rec': 0.55,\n",
       "   'roc_auc': 0.9919805535703257},\n",
       "  'ATG': {'f1': 0.6751543209876543,\n",
       "   'prc': 0.6396198830409356,\n",
       "   'rec': 0.7148692810457516,\n",
       "   'roc_auc': 0.9589901790567034},\n",
       "  'ATT': {'f1': 0.5490196078431373,\n",
       "   'prc': 0.6086956521739131,\n",
       "   'rec': 0.5,\n",
       "   'roc_auc': 0.9916290452351153},\n",
       "  'CTG': {'f1': 0.6693629929221436,\n",
       "   'prc': 0.645224171539961,\n",
       "   'rec': 0.6953781512605042,\n",
       "   'roc_auc': 0.9852017486769029},\n",
       "  'GTG': {'f1': 0.617351598173516,\n",
       "   'prc': 0.6462715105162524,\n",
       "   'rec': 0.5909090909090909,\n",
       "   'roc_auc': 0.9863136101826635},\n",
       "  'All': {'f1': 0.6532247641204602,\n",
       "   'prc': 0.6407200811359026,\n",
       "   'rec': 0.6662272607434748,\n",
       "   'roc_auc': 0.9843558318976546}},\n",
       " 'Val': {'ACG': {'f1': 0.626865671641791,\n",
       "   'prc': 0.6,\n",
       "   'rec': 0.65625,\n",
       "   'roc_auc': 0.9912146983311939},\n",
       "  'ATC': {'f1': 0.6818181818181819,\n",
       "   'prc': 0.6521739130434783,\n",
       "   'rec': 0.7142857142857143,\n",
       "   'roc_auc': 0.9956959706959707},\n",
       "  'ATG': {'f1': 0.7036144578313253,\n",
       "   'prc': 0.6728110599078341,\n",
       "   'rec': 0.7373737373737373,\n",
       "   'roc_auc': 0.9561884462393486},\n",
       "  'ATT': {'f1': 0.5945945945945946,\n",
       "   'prc': 0.55,\n",
       "   'rec': 0.6470588235294118,\n",
       "   'roc_auc': 0.9935726228475887},\n",
       "  'CTG': {'f1': 0.6444444444444444,\n",
       "   'prc': 0.6338797814207651,\n",
       "   'rec': 0.655367231638418,\n",
       "   'roc_auc': 0.9827556466054569},\n",
       "  'GTG': {'f1': 0.5669291338582678,\n",
       "   'prc': 0.6,\n",
       "   'rec': 0.5373134328358209,\n",
       "   'roc_auc': 0.9851384425958737},\n",
       "  'All': {'f1': 0.6571428571428571,\n",
       "   'prc': 0.6412639405204461,\n",
       "   'rec': 0.673828125,\n",
       "   'roc_auc': 0.9840212954699278}},\n",
       " 'Test': {'ACG': {'f1': 0.4912280701754386,\n",
       "   'prc': 0.42424242424242425,\n",
       "   'rec': 0.5833333333333334,\n",
       "   'roc_auc': 0.9841628959276019},\n",
       "  'ATC': {'f1': 0.5714285714285715,\n",
       "   'prc': 0.5555555555555556,\n",
       "   'rec': 0.5882352941176471,\n",
       "   'roc_auc': 0.9930470704602317},\n",
       "  'ATG': {'f1': 0.64375,\n",
       "   'prc': 0.6094674556213018,\n",
       "   'rec': 0.6821192052980133,\n",
       "   'roc_auc': 0.9575413548923483},\n",
       "  'ATT': {'f1': 0.5625,\n",
       "   'prc': 0.47368421052631576,\n",
       "   'rec': 0.6923076923076923,\n",
       "   'roc_auc': 0.9875325304121528},\n",
       "  'CTG': {'f1': 0.6355685131195334,\n",
       "   'prc': 0.6337209302325582,\n",
       "   'rec': 0.6374269005847953,\n",
       "   'roc_auc': 0.9829803033281229},\n",
       "  'GTG': {'f1': 0.6250000000000001,\n",
       "   'prc': 0.6493506493506493,\n",
       "   'rec': 0.6024096385542169,\n",
       "   'roc_auc': 0.9907205468100073},\n",
       "  'All': {'f1': 0.6230200633579726,\n",
       "   'prc': 0.6045081967213115,\n",
       "   'rec': 0.6427015250544662,\n",
       "   'roc_auc': 0.9838449823797362}}}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5c28b5fc-a785-4597-9fed-0a0f5780ece3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scores = pd.DataFrame(\n",
    "    unravel_scores(scores), \n",
    "    columns=['Dataset', 'Codon', 'ScoreType', 'ScoreVal'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afe65ce8-6af4-43e3-9bec-c97ab8af7565",
   "metadata": {},
   "source": [
    "Dump score, predictions, and predictions in bed format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "30c37fe8-0c0a-4e26-890e-5ffe1ac8fee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scores.to_csv(BASE / 'prediction_scores.tsv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3481bbf8-8e53-4110-bf11-4792ebc37c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred.to_csv(BASE / 'predictions_5UTR.tsv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "21342f96-3108-45d5-8cdd-e00a490d1a7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21098d64dd7f44288d1762006ef21fda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred2bed(df_pred, BASE / 'predictions_5UTR.tsv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "906c7c97-6ef4-4389-9432-ebd521502914",
   "metadata": {},
   "source": [
    "## Format tables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64df165d-9ef9-4d2f-af89-a97ff08df322",
   "metadata": {},
   "source": [
    "### Check correlations of predictions with signal values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d6954632-dd71-4c5a-af15-6a88adb32705",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((0.535706693063442, 0.0), (0.532731281037158, 0.0))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(pearsonr(df_pred.Signal.values, df_pred.y_prob), \n",
    " pearsonr(df_pred[df_pred.Dataset != 'Inference'].Signal.values, \n",
    "          df_pred[df_pred.Dataset != 'Inference'].y_prob))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09367c6f-0447-4e70-b829-e00be819ef32",
   "metadata": {},
   "source": [
    "### Format scores as latex table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "95b984a3-fa65-4bb6-9f69-555e4e2ad652",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_scores(df_scores):\n",
    "    \n",
    "    def format_codon_scores(group):\n",
    "        return group.groupby('ScoreType').apply(\n",
    "            lambda gg: ','.join(map(str, gg['ScoreVal'])))\n",
    "        \n",
    "    df = df_scores.copy()\n",
    "    df['ScoreVal'] = df['ScoreVal'].round(2)\n",
    "    return df.groupby('Codon').apply(format_codon_scores) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0a3b7ced-69f7-41e3-a357-7be4e1c2e257",
   "metadata": {},
   "outputs": [],
   "source": [
    "_df_scores = format_scores(df_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fb6767df-b677-491a-b801-19ec2db85969",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lllll}\n",
      "\\toprule\n",
      "ScoreType &              f1 &             prc &             rec &         roc\\_auc \\\\\n",
      "Codon &                 &                 &                 &                 \\\\\n",
      "\\midrule\n",
      "ACG   &  0.62,0.63,0.49 &   0.64,0.6,0.42 &   0.6,0.66,0.58 &  0.99,0.99,0.98 \\\\\n",
      "ATC   &  0.58,0.68,0.57 &  0.61,0.65,0.56 &  0.55,0.71,0.59 &   0.99,1.0,0.99 \\\\\n",
      "ATG   &   0.68,0.7,0.64 &  0.64,0.67,0.61 &  0.71,0.74,0.68 &  0.96,0.96,0.96 \\\\\n",
      "ATT   &  0.55,0.59,0.56 &  0.61,0.55,0.47 &   0.5,0.65,0.69 &  0.99,0.99,0.99 \\\\\n",
      "All   &  0.65,0.66,0.62 &   0.64,0.64,0.6 &  0.67,0.67,0.64 &  0.98,0.98,0.98 \\\\\n",
      "CTG   &  0.67,0.64,0.64 &  0.65,0.63,0.63 &   0.7,0.66,0.64 &  0.99,0.98,0.98 \\\\\n",
      "GTG   &  0.62,0.57,0.63 &   0.65,0.6,0.65 &   0.59,0.54,0.6 &  0.99,0.99,0.99 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_25924/1567027205.py:1: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  print(_df_scores.to_latex())\n"
     ]
    }
   ],
   "source": [
    "print(_df_scores.to_latex())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e40f280d-1e1d-468f-8b47-4f68efeb4a16",
   "metadata": {},
   "source": [
    "### Format codon counts for positive and negative classes across datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "198201a4-4da3-4a1a-a4e2-dbd9fb5e6b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_counts(df_counts):\n",
    "    \n",
    "    def format_codon_counts(group):\n",
    "        return group.groupby('Dataset').apply(\n",
    "            lambda gg: '/'.join(map(str, list(gg['Start'])[::-1])))\n",
    "        \n",
    "    df = df_counts.copy()\n",
    "    return df.groupby('Codon').apply(format_codon_counts) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ada299fd-3151-4f74-8dcc-dea13144abfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = df_pred.loc[\n",
    "    df_pred.Dataset != 'Inference', \n",
    "    ['Dataset', 'Codon', 'y_true', 'Start']\n",
    "].groupby(\n",
    "    ['Dataset', 'Codon', 'y_true'], as_index=False).count()\n",
    "counts = pd.concat([counts[counts.Dataset == ds_name] for ds_name in ['Train', 'Val', 'Test']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "56386334-17b2-4353-9c7b-445bc5d9ca10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Dataset</th>\n",
       "      <th>Test</th>\n",
       "      <th>Train</th>\n",
       "      <th>Val</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Codon</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ACG</th>\n",
       "      <td>24/1326</td>\n",
       "      <td>289/11131</td>\n",
       "      <td>32/1558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ATC</th>\n",
       "      <td>17/2022</td>\n",
       "      <td>140/16191</td>\n",
       "      <td>21/2080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ATG</th>\n",
       "      <td>151/2079</td>\n",
       "      <td>1224/16511</td>\n",
       "      <td>198/2161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ATT</th>\n",
       "      <td>13/2542</td>\n",
       "      <td>140/19176</td>\n",
       "      <td>17/2709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CTG</th>\n",
       "      <td>171/5623</td>\n",
       "      <td>1428/46792</td>\n",
       "      <td>177/6354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GTG</th>\n",
       "      <td>83/3751</td>\n",
       "      <td>572/30837</td>\n",
       "      <td>67/3976</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Dataset      Test       Train       Val\n",
       "Codon                                  \n",
       "ACG       24/1326   289/11131   32/1558\n",
       "ATC       17/2022   140/16191   21/2080\n",
       "ATG      151/2079  1224/16511  198/2161\n",
       "ATT       13/2542   140/19176   17/2709\n",
       "CTG      171/5623  1428/46792  177/6354\n",
       "GTG       83/3751   572/30837   67/3976"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "format_counts(counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ad74afc-66eb-463e-a675-47366ca71ac5",
   "metadata": {},
   "source": [
    "### Check overall codon counts in modeling dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a7821b9f-c70c-4e79-ba49-501c27dadeb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts_total = counts.groupby(\n",
    "    ['Codon', 'y_true'], as_index=False\n",
    ").agg({'Start': 'sum'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "40ac6f2c-fdfb-46da-989a-22b27d6fc23d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Codon\n",
       "ACG      (14015, 345, 14360, 2.402506963788301)\n",
       "ATC     (20293, 178, 20471, 0.8695227394851253)\n",
       "ATG     (20751, 1573, 22324, 7.046228274502778)\n",
       "ATT     (24427, 170, 24597, 0.6911411960808228)\n",
       "CTG    (58769, 1776, 60545, 2.9333553555206873)\n",
       "GTG      (38564, 722, 39286, 1.837804815964975)\n",
       "dtype: object"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def infer_balance(gg):\n",
    "    neg, pos = gg['Start'].values\n",
    "    total = neg + pos\n",
    "    return neg, pos, total, pos / total * 100\n",
    "\n",
    "counts_total.groupby('Codon').apply(infer_balance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44901d6b-6f78-4a3b-bfc9-c2c29c04ebf8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "76153679-83ac-4e64-91df-3c9556f3d6a7",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Predict 5'UTR TISs\n",
    "\n",
    "Here, we'll use the fine-tuned `uBERTa_classifier` to predict TISs in 5'UTR sequences of the protein-coding genes of the human genome."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ec1264-7204-4904-9b1f-960b90e76e7b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Prerequisites\n",
    "\n",
    "This notebook requires:\n",
    "- [DS_BASE](https://drive.google.com/file/d/15fQP5ldYNvV1YY2T2Qza9CNFdYj4zZg8/view?usp=sharing) (`../data/DS_BASE_v4.7_seqs.tsv`)\n",
    "- [dataset_labeling](https://drive.google.com/file/d/1-R1zLJRrJg3KXAaqDe9T60s9MXdrv4RO/view?usp=sharing) (`../data/dataset_labeling_v.4.7.tsv`)\n",
    "- [trained_model](https://drive.google.com/file/d/1weL5Wp3DrCIoW-kCxJ6aIveYZyQQbDOQ/view?usp=sharing) (`../models/ws100_step20_AAG_ACG_AGG_ATA_ATC_ATG_ATT_CTG_GTG_TTG_nopretrain_tokenlevel_signal`)\n",
    "\n",
    "One can either download or obtain the requirements manually: `prepare_base_dataset.ipynb` for the first two, and `train_uBERTa.ipynb` for the trained model.\n",
    "\n",
    "For instance, starting from the project's root:\n",
    "```bash\n",
    "gdown --fuzzy https://drive.google.com/file/d/15fQP5ldYNvV1YY2T2Qza9CNFdYj4zZg8/view?usp=sharing\n",
    "gdown --fuzzy https://drive.google.com/file/d/1-R1zLJRrJg3KXAaqDe9T60s9MXdrv4RO/view?usp=sharing\n",
    "tar -xzf DS_BASE_v4.7_seqs.tsv.tar.gz\n",
    "tar -xzf dataset_labeling_v4.7.tsv.tar.gz\n",
    "mkdir -p ../models\n",
    "cd ../models\n",
    "gdown --https://drive.google.com/file/d/1weL5Wp3DrCIoW-kCxJ6aIveYZyQQbDOQ/view?usp=sharing\n",
    "tar -xzf ws100_step20_AAG_ACG_AGG_ATA_ATC_ATG_ATT_CTG_GTG_TTG_nopretrain_tokenlevel_signal.tar.gz\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b1b7602-f1a3-4027-a176-21d7cbeb93bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import operator as op\n",
    "from itertools import chain\n",
    "from math import ceil\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "from more_itertools import sliced, unzip\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.metrics import f1_score, recall_score, precision_score, roc_auc_score, balanced_accuracy_score\n",
    "from torch.utils.data import DataLoader, SequentialSampler, TensorDataset\n",
    "from tqdm.auto import tqdm\n",
    "from transformers import DistilBertConfig\n",
    "\n",
    "from uBERTa.base import VALID_START\n",
    "from uBERTa.loader import uBERTaLoader\n",
    "from uBERTa.model import uBERTa_classifier, WeightedDistilBertClassifier2\n",
    "from uBERTa.tokenizer import DNATokenizer\n",
    "from uBERTa.utils import split_values, kmerize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "042258da-4eb4-4c3d-afdf-1600003ee8c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_SEQ_SIZE = 30\n",
    "MAX_SEQ_SIZE = 3000\n",
    "WINDOW = 100\n",
    "STEP = WINDOW // 5\n",
    "BATCH_SIZE = 2 ** 10\n",
    "\n",
    "BASE = Path('../data/NN_pred')\n",
    "BASE.mkdir(exist_ok=True)\n",
    "DATA = BASE.parent\n",
    "MODEL_PATH = Path('../models/ws100_step20_AAG_ACG_AGG_ATA_ATC_ATG_ATT_CTG_GTG_TTG_nopretrain_tokenlevel_signal/')\n",
    "DS = DATA / 'DS_BASE_v4.7_seqs.tsv'\n",
    "DS_LABELS = DATA / 'dataset_labeling_v4.7.tsv'\n",
    "STARTS = VALID_START"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e265e04a-e7af-4429-bfeb-39cc966ac1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fa6175c1-de8e-434d-83e0-cc9648894ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_base(path_base, path_labels, min_seq_size, max_seq_size):\n",
    "    \"\"\"\n",
    "    Read base dataset, merge gene labels (splitting genes into Train, \n",
    "        Test, and Valiation) and filter by seq size\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(path_base, sep='\\t')\n",
    "    df['SeqSize'] = df['Seq'].apply(len)\n",
    "    print(f'Initial ds: {len(df)}')\n",
    "    df_labels = pd.read_csv(path_labels, sep='\\t')\n",
    "    df = df.merge(df_labels, on='GeneID', how='left')\n",
    "    df = df[(df.SeqSize >= min_seq_size) & (df.SeqSize <= max_seq_size)]\n",
    "    print(f'Conforming to size threshold: {len(df)}')\n",
    "    split_values(df, 'SeqEnum')\n",
    "    split_values(df, 'Classes')\n",
    "    split_values(df, 'Signal', dtype=float)\n",
    "    return df\n",
    "\n",
    "def aggregate_predictions(predictions):\n",
    "    \"\"\"\n",
    "    Detach and concatenate raw batch predictions\n",
    "    \"\"\"\n",
    "    y_prob = [x[1].detach().cpu().numpy()[:, 1] for x in predictions]\n",
    "    y_true = [x[2].detach().cpu().numpy() for x in predictions]\n",
    "    \n",
    "    return np.concatenate(y_prob), np.concatenate(y_true)\n",
    "\n",
    "# def safe_take_fst(xs):\n",
    "#     assert len(xs.unique()) == 1\n",
    "#     return xs.iloc[0]\n",
    "\n",
    "# def take_fst(xs):\n",
    "#     return xs.iloc[0]\n",
    "\n",
    "# def unravel_base_ds(path, keep_cols=('GeneID', 'TranscriptID')):\n",
    "#     \"\"\"\n",
    "#     Unravel sequence data of the base dataset into the codon-per-row format.\n",
    "#     \"\"\"\n",
    "    \n",
    "#     def unravel_row(row):\n",
    "#         keep_values = [row[col] for col in keep_cols]\n",
    "#         for i, (codon, en, cls) in enumerate(\n",
    "#             zip(row.Seq.split(), row.SeqEnum, row.Classes)\n",
    "#         ):\n",
    "#             if cls != -100:\n",
    "#                 yield (row.Chrom, row.Strand, en, codon, *keep_values)\n",
    "    \n",
    "#     df = pd.read_csv(path, sep='\\t')\n",
    "#     split_values(df, 'SeqEnum')\n",
    "#     df['Seq'] = df['Seq'].apply(lambda s: kmerize(s, 3))\n",
    "#     unraveled = chain.from_iterable(\n",
    "#         map(unravel_row, map(op.itemgetter(1), df.iterrows())))\n",
    "#     # print(next(unraveled))\n",
    "\n",
    "#     return pd.DataFrame(\n",
    "#         unraveled,\n",
    "#         columns=['Chrom', 'Strand', 'Start', 'Codon'] + list(keep_cols))\n",
    "\n",
    "\n",
    "# def center_ds(df: pd.DataFrame):\n",
    "#     def unravel(row):\n",
    "#         mask = row.Classes != -100\n",
    "#         seq = row['Seq'].split()\n",
    "#         sig = row['Signal']\n",
    "\n",
    "#         prepend_values = [row[c] for c in cols_prepend]\n",
    "#         for idx in np.where(mask)[0]:\n",
    "#             pos = row['SeqEnum'][idx]\n",
    "#             cls = row['Classes'][idx]\n",
    "#             start = ''.join(seq_c[RNA_SIDE: RNA_SIDE + 3])\n",
    "#             yield *prepend_values, seq_c, start, cls, pos, sig_c\n",
    "\n",
    "#     cols_roll = ['Seq', 'Start', 'Classes', 'SeqEnum', 'Signal']\n",
    "#     cols_prepend = [c for c in df.columns if c not in cols_roll]\n",
    "#     columns = cols_prepend + cols_roll\n",
    "\n",
    "#     rows = tqdm(df.iterrows(), total=len(df), desc='Unraveling')\n",
    "\n",
    "#     unraveled = chain.from_iterable(map(unravel, map(op.itemgetter(1), rows)))\n",
    "\n",
    "#     return pd.DataFrame(unraveled, columns=columns)\n",
    "\n",
    "\n",
    "# def unravel_and_group(df, y_prob, y_true, threshold=0.5, pred_agg='mean'):\n",
    "#     \"\"\"\n",
    "#     Unravel sequences in the dataset to restructure as codon-per-row.\n",
    "#     Aggregate predictions for the same codon.\n",
    "#     \"\"\"\n",
    "#     def unravel_row(row):\n",
    "#         for i, (codon, en, cls, sig) in enumerate(\n",
    "#             zip(row.Seq.split(), row.SeqEnum, row.Classes, row.Signal)\n",
    "#         ):\n",
    "#             if cls != -100:\n",
    "#                 yield row.Chrom, row.Strand, en, codon, cls, sig, row.Dataset\n",
    "    \n",
    "#     # Unravel the dataset with predictions\n",
    "#     unraveled = map(unravel_row, map(op.itemgetter(1), df.iterrows()))\n",
    "#     _df = pd.DataFrame(\n",
    "#         chain.from_iterable(unraveled), \n",
    "#         columns=['Chrom', 'Strand', 'Start', 'Codon', \n",
    "#                  'Label', 'Signal', 'Dataset'])\n",
    "    \n",
    "#     # This serves as additional sanity check\n",
    "#     # working iff the number of codons match\n",
    "#     _df['y_prob'] = np.squeeze(y_prob[:, 1])  # Take the probability of the positive class\n",
    "#     _df['y_true'] = np.squeeze(y_true)\n",
    "    \n",
    "#     _df = _df[_df.Start != 0]\n",
    "    \n",
    "#     # Average the predictions for each start codon across transcripts and windows\n",
    "#     _df = _df.groupby(\n",
    "#         ['Chrom', 'Strand', 'Start', 'Codon'], \n",
    "#         as_index=False\n",
    "#     ).agg({\n",
    "#         'y_prob': pred_agg, \n",
    "#         'y_true': safe_take_fst,\n",
    "#         'Signal': take_fst,\n",
    "#         'Dataset': take_fst,\n",
    "#     })\n",
    "    \n",
    "#     _df['y_pred'] = (_df['y_prob'] > threshold).astype(int)\n",
    "    \n",
    "#     return _df\n",
    "\n",
    "def calc_pred_scores(df):\n",
    "    y_prob = df['y_prob'].values\n",
    "    y_pred = df['y_pred'].values\n",
    "    y_true = df['y_true'].values\n",
    "    fn, fp, tn, tp = map(\n",
    "        lambda x: len(df[df.PredictionType == x]), \n",
    "        ['FN', 'FP', 'TN', 'TP'])\n",
    "    return {\n",
    "        'f1': f1_score(y_true, y_pred, zero_division=0), \n",
    "        'prc': precision_score(y_true, y_pred, zero_division=0), \n",
    "        'rec': recall_score(y_true, y_pred, zero_division=0),\n",
    "        'bac': balanced_accuracy_score(y_true, y_pred),\n",
    "        'FN': fn, 'FP': fp, 'TN': tn, 'TP': tp,\n",
    "    }\n",
    "\n",
    "def annotate_predictions(df):\n",
    "    df = df.copy()\n",
    "    df.loc[(df.y_true == 1) & (df.y_pred == 1), 'PredictionType'] = 'TP'\n",
    "    df.loc[(df.y_true == 1) & (df.y_pred == 0), 'PredictionType'] = 'FN'\n",
    "    df.loc[(df.y_true == 0) & (df.y_pred == 1), 'PredictionType'] = 'FP'\n",
    "    df.loc[(df.y_true == 0) & (df.y_pred == 0), 'PredictionType'] = 'TN'\n",
    "    return df\n",
    "\n",
    "def score(df, threshold):\n",
    "    df = df.copy()\n",
    "    df['y_true'] = df['y_true'].astype(int)\n",
    "    scores = {\n",
    "        codon: calc_pred_scores(group, threshold) \n",
    "        for codon, group in df.groupby('Seq')}\n",
    "    scores['All'] = calc_pred_scores(df, threshold)\n",
    "    return scores\n",
    "\n",
    "def split_into_loaders(tds, chunk_size, batch_size = 2 ** 8):\n",
    "    for tensors in sliced(tds, chunk_size):\n",
    "        tensors = list(tensors)\n",
    "        if all(x.shape[0] > 0 for x in tensors):\n",
    "            _tds = TensorDataset(*tensors)\n",
    "            yield DataLoader(\n",
    "                _tds, \n",
    "                sampler=SequentialSampler(_tds), \n",
    "                batch_size=batch_size,\n",
    "                num_workers=4)\n",
    "        else:\n",
    "            return\n",
    "        \n",
    "# def split_df(df, chunk_size):\n",
    "#     n = ceil(len(df) // chunk_size)\n",
    "#     for i in range(n):\n",
    "#         yield df.iloc[i * chunk_size: (i + 1) * chunk_size]\n",
    "\n",
    "# def predict(loader, ds, model, trainer, threshold, agg_fn):\n",
    "#     predictions = trainer.predict(model, loader)\n",
    "#     y_prob, y_true = aggregate_predictions(predictions)\n",
    "#     df = unravel_and_group(ds, y_prob, y_true, threshold, agg_fn)\n",
    "#     return df\n",
    "\n",
    "def agg_y_true(vs):\n",
    "    if len(vs) == 1:\n",
    "        return vs\n",
    "    s = set(vs)\n",
    "    if len(s) > 1:\n",
    "        return ';'.join(map(str, vs))\n",
    "    return s.pop()\n",
    "\n",
    "def unravel_scores(scores):\n",
    "    for ds_name, ds_vs in scores.items():\n",
    "        for codon_name, codon_scores in ds_vs.items():\n",
    "            for score_name, score_val in codon_scores.items():\n",
    "                yield ds_name, codon_name, score_name, score_val\n",
    "                \n",
    "def get_color(y_pred, y_true, dataset):\n",
    "    \"\"\" Make RGB colors for the bed file based on the prediction type\"\"\"\n",
    "    green, blue, red, black = (\n",
    "        '0,255,0', '0,0,255', '255,0,0', '0,0,0')\n",
    "    if dataset == 'Inference':\n",
    "        if y_pred == 1:\n",
    "            return green  # Inference positive\n",
    "        return blue       # Inference negative\n",
    "    if y_pred == 1 and y_true == 1:\n",
    "        return green      # TP\n",
    "    if y_pred == 0 and y_true == 0:\n",
    "        return blue       # TN\n",
    "    if y_pred == 0 and y_true == 1:\n",
    "        return red        # FN\n",
    "    return black          # FP\n",
    "\n",
    "def wrap_row(row, ts=0.5):\n",
    "    label = row.Dataset\n",
    "    color = get_color(row.y_pred, row.y_true, row.Dataset)\n",
    "    start = row.SeqEnum if row.Strand == '+' else row.SeqEnum - 2\n",
    "    end = start + 3\n",
    "    return (f'{row.Chrom} {start} {end} {label} '\n",
    "            f'{int(row.y_prob * 100)} {row.Strand} {start} {end} {color}')\n",
    "\n",
    "def pred2bed(df, out_path):\n",
    "    with open(out_path, 'w') as f:\n",
    "        print('track name=\"uBERTa predictions v4.7\" itemRgb=\"On\"', file=f)\n",
    "        for _, row in tqdm(df.iterrows()):\n",
    "            print(wrap_row(row), file=f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a19bf875-4aef-4a9f-9d1d-9855be773680",
   "metadata": {},
   "source": [
    "## Prepare data\n",
    "\n",
    "We'll initalize `uBERTaLoader` without base dataset and use its methods to prepare the sequence data for predictions. This will take care of encoding inputs and sliding the window over the sequence data. Be careful to use the same setup as in `train_uBERTa.ipynb`, especially wrt window parameters and experimental signal bounds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "718dea0b-e1be-43c7-b940-f13303650dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = DNATokenizer(kmer=3)\n",
    "loader = uBERTaLoader(\n",
    "    None, WINDOW, STEP, tokenizer, \n",
    "    scale_signal_bounds=(0.0, 10.0),\n",
    "    is_mlm_task=False,\n",
    "    valid_start_codons=STARTS,\n",
    "    batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7fa02af3-4b1e-48d8-8f18-1e4af1f0d677",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial ds: 79453\n",
      "Conforming to size threshold: 73797\n"
     ]
    }
   ],
   "source": [
    "ds = parse_base(DS, DS_LABELS, MIN_SEQ_SIZE, MAX_SEQ_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fef3df01-cb98-4efa-8195-9ece8e85e14e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:uBERTa.loader:Preparing Main with 73797 records for token-level task\n",
      "INFO:uBERTa.loader:Using kmer 3 on ('Seq', 'SeqEnum', 'Signal', 'Classes')\n",
      "DEBUG:uBERTa.loader:Reducing kmers for Main\n",
      "/home/ivan/miniconda3/envs/uberta/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3162: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return asarray(a).ndim\n",
      "DEBUG:uBERTa.loader:Filtering to ('AAG', 'ACG', 'AGG', 'ATA', 'ATC', 'ATG', 'ATT', 'CTG', 'GTG', 'TTG') for Main\n",
      "DEBUG:uBERTa.loader:Capping and scaling signal for Main\n",
      "DEBUG:uBERTa.loader:Capped signal in (0.1, 5000.0)\n",
      "DEBUG:uBERTa.loader:Scaled signal between 0 and 1. Min 0.1, Max 5000.0\n",
      "INFO:uBERTa.loader:Rolling window with size 98, step 20\n",
      "WARNING:uBERTa.loader:Removing 295 out of 697739 windows without classes from Main. Consider calibrating window parameters.\n"
     ]
    }
   ],
   "source": [
    "ds = loader._prep_token_level(\n",
    "    ds, 'Main'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "63a5dfac-d279-445f-83c6-8ddc9c0b1e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.drop(columns='SeqSize')\n",
    "ds.loc[ds.Dataset.isna(), 'Dataset'] = 'Inference'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "25da0424-b919-4699-9d3b-7579ea3f254d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tds = loader._prep_tds_cls(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d9fffda6-a49d-4882-b4dc-9d8dc97e3688",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(tds, DATA / 'tds.torch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "82de457b-d4aa-435d-b924-e08560f8a42e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds['Seq'] = ds['Seq'].apply(lambda x: np.array(x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0f0aa193-ea23-4807-86e8-58d5c119fff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_indices = [np.where(x != -100)[0] for x in ds['Classes']]\n",
    "for col in ['Seq', 'Classes', 'SeqEnum', 'Signal']:\n",
    "    ds[col] = [x[i] for i, x in zip(cls_indices, ds[col])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1fff7589-7174-4887-aecc-9b95e8b651e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ds.explode(['Seq', 'Classes', 'SeqEnum', 'Signal'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a743fa9c-857f-4b23-b2ae-5666ad2a3614",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.to_csv(DATA / 'base_unraveled.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74fa78cb-d5a9-4374-b67c-6a178dd61355",
   "metadata": {},
   "source": [
    "## Init loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a8497369-121d-48dd-b981-431d559471fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tds = torch.load(DATA / 'tds.torch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f10da35c-c862-49a1-83cd-2974d9d085fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predict_loader = DataLoader(\n",
    "    tds, \n",
    "    sampler=SequentialSampler(tds), \n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_workers=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c7fb6dd-f3e0-4897-ad12-e5ba25063f4b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2c96641b-9ac2-4cc4-a940-859e1dcf8ef8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ../models/ws100_step20_AAG_ACG_AGG_ATA_ATC_ATG_ATT_CTG_GTG_TTG_nopretrain_tokenlevel_signal were not used when initializing WeightedDistilBertClassifier2: ['loss.weight']\n",
      "- This IS expected if you are initializing WeightedDistilBertClassifier2 from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing WeightedDistilBertClassifier2 from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "config = DistilBertConfig.from_pretrained(MODEL_PATH)\n",
    "model = uBERTa_classifier(\n",
    "    model=WeightedDistilBertClassifier2,\n",
    "    config=config,\n",
    ")\n",
    "model.model = model.model.from_pretrained(MODEL_PATH)\n",
    "model.model.config.use_signal = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e93cf1ec-502b-4750-b824-e43cfe82d48f",
   "metadata": {},
   "source": [
    "## Predict\n",
    "\n",
    "- Using the whole dataset may overflow RAM, hence we'll split loaders into sizeable chunks and predict them separately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ba746f19-7f3e-4423-a4bd-3e9bc0102359",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit native Automatic Mixed Precision (AMP)\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n"
     ]
    }
   ],
   "source": [
    "gpus = [0]\n",
    "trainer = pl.Trainer(\n",
    "    accelerator=\"gpu\",\n",
    "    precision=16,\n",
    "    gpus=gpus,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7697c9d0-165f-4929-9601-524fe15691e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29ab048a3d61417eb9fda650a8c06826",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93aaf1a21a904f5185c6bc3e173befc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ffd8242a3ca482fbdf8963d8672788e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "096f876fd0764c19872bc936135176e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cd3e756b6d942bbbda3be831487841d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a15814a3935641aaa9e47bb4a38ec6e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90d243e994a4456a97e71ef9021d9335",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "chunk_size = 100000\n",
    "loaders = list(split_into_loaders(tds, chunk_size, BATCH_SIZE))\n",
    "predictions = [aggregate_predictions(trainer.predict(model, l)) for l in loaders]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aecf5b6f-1dec-4835-b7d8-07cbdf074a53",
   "metadata": {},
   "source": [
    "## Parse and dump results\n",
    "\n",
    "- Predictions are outputted for each valid start codon.\n",
    "- As a result, the number of predicted instances and their order must match those in the `base_unraveled` prepared above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "80433ff6-e8dc-44ba-bc0c-46b008bc8b20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((9568908,), (9568908,))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prob, y_true = map(np.concatenate, map(list, unzip(predictions)))\n",
    "y_prob.shape, y_true.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "de748991-11f9-4cb0-b81c-7f05fba22b8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9568908"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cds = pd.read_csv(DATA / 'base_unraveled.csv')\n",
    "len(cds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "faa9e386-f889-4627-bd4e-b26a90690a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "cds['y_prob'] = y_prob\n",
    "cds['y_true'] = y_true"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f52c705-d146-4ee0-be01-43a95299f418",
   "metadata": {},
   "source": [
    "- We double-check that the true classes outputted by model and those within the `base_unraveled` match exactly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "031c7f4b-0b07-4d1d-b226-24a3251c2626",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "not len(cds[cds.Classes != cds.y_true])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52078602-0c2b-4893-9073-9a81c994cda6",
   "metadata": {},
   "source": [
    "- Explicitly mark the \"inference\" dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "90f9d75f-7ebc-4d88-958e-361c067f1917",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = cds.Dataset == 'Inference'\n",
    "cds.loc[idx, 'y_true'] = -1\n",
    "cds.loc[idx, 'Classes'] = -1\n",
    "cds.loc[idx, 'Dataset'] = 'Inference'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "93f1f2b0-95d9-4c3f-8d56-c39692590ef2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Chrom</th>\n",
       "      <th>Strand</th>\n",
       "      <th>TranscriptID</th>\n",
       "      <th>GeneID</th>\n",
       "      <th>SeqSize</th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Seq</th>\n",
       "      <th>Classes</th>\n",
       "      <th>SeqEnum</th>\n",
       "      <th>Signal</th>\n",
       "      <th>y_prob</th>\n",
       "      <th>y_true</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>chr1</td>\n",
       "      <td>+</td>\n",
       "      <td>ENST00000003912</td>\n",
       "      <td>ENSG00000001461</td>\n",
       "      <td>715</td>\n",
       "      <td>Inference</td>\n",
       "      <td>ATT</td>\n",
       "      <td>-1</td>\n",
       "      <td>24415803</td>\n",
       "      <td>0.001800</td>\n",
       "      <td>0.000878</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>chr1</td>\n",
       "      <td>+</td>\n",
       "      <td>ENST00000003912</td>\n",
       "      <td>ENSG00000001461</td>\n",
       "      <td>715</td>\n",
       "      <td>Inference</td>\n",
       "      <td>TTG</td>\n",
       "      <td>-1</td>\n",
       "      <td>24415804</td>\n",
       "      <td>0.001800</td>\n",
       "      <td>0.000853</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>chr1</td>\n",
       "      <td>+</td>\n",
       "      <td>ENST00000003912</td>\n",
       "      <td>ENSG00000001461</td>\n",
       "      <td>715</td>\n",
       "      <td>Inference</td>\n",
       "      <td>AAG</td>\n",
       "      <td>-1</td>\n",
       "      <td>24415809</td>\n",
       "      <td>0.003800</td>\n",
       "      <td>0.000697</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>chr1</td>\n",
       "      <td>+</td>\n",
       "      <td>ENST00000003912</td>\n",
       "      <td>ENSG00000001461</td>\n",
       "      <td>715</td>\n",
       "      <td>Inference</td>\n",
       "      <td>AGG</td>\n",
       "      <td>-1</td>\n",
       "      <td>24415810</td>\n",
       "      <td>0.081802</td>\n",
       "      <td>0.011008</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>chr1</td>\n",
       "      <td>+</td>\n",
       "      <td>ENST00000003912</td>\n",
       "      <td>ENSG00000001461</td>\n",
       "      <td>715</td>\n",
       "      <td>Inference</td>\n",
       "      <td>ATG</td>\n",
       "      <td>-1</td>\n",
       "      <td>24415814</td>\n",
       "      <td>0.335807</td>\n",
       "      <td>0.921499</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Chrom Strand     TranscriptID           GeneID  SeqSize    Dataset  Seq  \\\n",
       "0  chr1      +  ENST00000003912  ENSG00000001461      715  Inference  ATT   \n",
       "1  chr1      +  ENST00000003912  ENSG00000001461      715  Inference  TTG   \n",
       "2  chr1      +  ENST00000003912  ENSG00000001461      715  Inference  AAG   \n",
       "3  chr1      +  ENST00000003912  ENSG00000001461      715  Inference  AGG   \n",
       "4  chr1      +  ENST00000003912  ENSG00000001461      715  Inference  ATG   \n",
       "\n",
       "   Classes   SeqEnum    Signal    y_prob  y_true  \n",
       "0       -1  24415803  0.001800  0.000878      -1  \n",
       "1       -1  24415804  0.001800  0.000853      -1  \n",
       "2       -1  24415809  0.003800  0.000697      -1  \n",
       "3       -1  24415810  0.081802  0.011008      -1  \n",
       "4       -1  24415814  0.335807  0.921499      -1  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cds.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "255b062e-1665-432f-a1cb-4a7badf44a3d",
   "metadata": {},
   "source": [
    "- Group predictions by positions (across transcripts and slices created by the sliding window approach)\n",
    "- Aggregate predictions:\n",
    "    - Merge genes.\n",
    "    - Merge transcripts.\n",
    "    - Safely aggregate y_true; there should be no positions having opposing `y_true` labels.\n",
    "    - Take average probability of predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7cda95dc-2e18-46ff-a92b-fb148c030cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cds = cds.groupby(\n",
    "        ['Chrom', 'Strand', 'Seq', 'SeqEnum', 'Dataset'], \n",
    "        as_index=False\n",
    "    ).agg(\n",
    "    {\n",
    "        'GeneID':  lambda vs: ';'.join(sorted(set(vs))),\n",
    "        'TranscriptID': lambda vs: ';'.join(sorted(set(vs))),\n",
    "        'y_true': agg_y_true,\n",
    "        'y_prob': 'mean',\n",
    "})\n",
    "# len(cds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "76978cb3-b0d8-4877-a469-0e8dfc2ea996",
   "metadata": {},
   "outputs": [],
   "source": [
    "cds['y_pred'] = (cds['y_prob'] > 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c8debeae-62de-4886-b9a8-4ff01c4dc8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "cds = annotate_predictions(cds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "83e75c59-4e3b-4c73-8242-8a0ab593b169",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1421737"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "99a72499-efa3-4a28-a962-1fa307f15798",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1    1100276\n",
       " 0     316056\n",
       " 1       5405\n",
       "Name: y_true, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cds.y_true.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d42b9b01-6236-452b-abb3-cc474609169f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cds = cds[\n",
    "    ['GeneID', 'TranscriptID', 'Chrom', 'Strand', 'Seq', 'SeqEnum',\n",
    "     'Dataset', 'y_true', 'y_pred', 'y_prob', 'PredictionType']\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab9c430-453c-43ed-a40c-08b40de67a96",
   "metadata": {},
   "source": [
    "- Score predictions per dataset and codon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "21771568-5acf-49b2-9c74-11967570aa43",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = {ds_name: score(cds[cds.Dataset == ds_name]) for ds_name in ('Train', 'Val', 'Test')}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b53c8e-b0c5-463e-a3ac-0c661bd3be6f",
   "metadata": {},
   "source": [
    "- Format the table for easier visual representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5c28b5fc-a785-4597-9fed-0a0f5780ece3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ScoreType</th>\n",
       "      <th>f1</th>\n",
       "      <th>prc</th>\n",
       "      <th>rec</th>\n",
       "      <th>bac</th>\n",
       "      <th>TN</th>\n",
       "      <th>FN</th>\n",
       "      <th>FP</th>\n",
       "      <th>TP</th>\n",
       "      <th>P</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dataset</th>\n",
       "      <th>Codon</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"11\" valign=\"top\">Test</th>\n",
       "      <th>All</th>\n",
       "      <td>0.61</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.91</td>\n",
       "      <td>29746</td>\n",
       "      <td>98</td>\n",
       "      <td>526</td>\n",
       "      <td>486</td>\n",
       "      <td>584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CTG</th>\n",
       "      <td>0.64</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.93</td>\n",
       "      <td>5502</td>\n",
       "      <td>23</td>\n",
       "      <td>173</td>\n",
       "      <td>171</td>\n",
       "      <td>194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ATG</th>\n",
       "      <td>0.62</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1783</td>\n",
       "      <td>20</td>\n",
       "      <td>163</td>\n",
       "      <td>150</td>\n",
       "      <td>170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GTG</th>\n",
       "      <td>0.63</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.90</td>\n",
       "      <td>3733</td>\n",
       "      <td>16</td>\n",
       "      <td>65</td>\n",
       "      <td>69</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACG</th>\n",
       "      <td>0.60</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.89</td>\n",
       "      <td>1376</td>\n",
       "      <td>8</td>\n",
       "      <td>41</td>\n",
       "      <td>36</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TTG</th>\n",
       "      <td>0.58</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.84</td>\n",
       "      <td>3032</td>\n",
       "      <td>14</td>\n",
       "      <td>29</td>\n",
       "      <td>30</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ATC</th>\n",
       "      <td>0.68</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.92</td>\n",
       "      <td>1907</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>21</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ATT</th>\n",
       "      <td>0.37</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.79</td>\n",
       "      <td>2336</td>\n",
       "      <td>6</td>\n",
       "      <td>25</td>\n",
       "      <td>9</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ATA</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1307</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAG</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>3758</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AGG</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>5012</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"11\" valign=\"top\">Train</th>\n",
       "      <th>All</th>\n",
       "      <td>0.57</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.91</td>\n",
       "      <td>251248</td>\n",
       "      <td>693</td>\n",
       "      <td>4681</td>\n",
       "      <td>3580</td>\n",
       "      <td>4273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CTG</th>\n",
       "      <td>0.60</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.92</td>\n",
       "      <td>46597</td>\n",
       "      <td>173</td>\n",
       "      <td>1517</td>\n",
       "      <td>1264</td>\n",
       "      <td>1437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ATG</th>\n",
       "      <td>0.59</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.89</td>\n",
       "      <td>15329</td>\n",
       "      <td>187</td>\n",
       "      <td>1483</td>\n",
       "      <td>1210</td>\n",
       "      <td>1397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GTG</th>\n",
       "      <td>0.57</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.90</td>\n",
       "      <td>30908</td>\n",
       "      <td>108</td>\n",
       "      <td>595</td>\n",
       "      <td>469</td>\n",
       "      <td>577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACG</th>\n",
       "      <td>0.55</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.92</td>\n",
       "      <td>11096</td>\n",
       "      <td>32</td>\n",
       "      <td>353</td>\n",
       "      <td>236</td>\n",
       "      <td>268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TTG</th>\n",
       "      <td>0.54</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.86</td>\n",
       "      <td>25186</td>\n",
       "      <td>67</td>\n",
       "      <td>247</td>\n",
       "      <td>187</td>\n",
       "      <td>254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ATC</th>\n",
       "      <td>0.47</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.90</td>\n",
       "      <td>16494</td>\n",
       "      <td>25</td>\n",
       "      <td>210</td>\n",
       "      <td>103</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ATT</th>\n",
       "      <td>0.49</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.86</td>\n",
       "      <td>19506</td>\n",
       "      <td>35</td>\n",
       "      <td>157</td>\n",
       "      <td>92</td>\n",
       "      <td>127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ATA</th>\n",
       "      <td>0.30</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.69</td>\n",
       "      <td>11694</td>\n",
       "      <td>25</td>\n",
       "      <td>44</td>\n",
       "      <td>15</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AGG</th>\n",
       "      <td>0.10</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.56</td>\n",
       "      <td>42640</td>\n",
       "      <td>27</td>\n",
       "      <td>48</td>\n",
       "      <td>4</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAG</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>31798</td>\n",
       "      <td>14</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"11\" valign=\"top\">Val</th>\n",
       "      <th>All</th>\n",
       "      <td>0.57</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.90</td>\n",
       "      <td>29274</td>\n",
       "      <td>97</td>\n",
       "      <td>581</td>\n",
       "      <td>451</td>\n",
       "      <td>548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ATG</th>\n",
       "      <td>0.62</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1737</td>\n",
       "      <td>20</td>\n",
       "      <td>198</td>\n",
       "      <td>180</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CTG</th>\n",
       "      <td>0.57</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.92</td>\n",
       "      <td>5265</td>\n",
       "      <td>21</td>\n",
       "      <td>180</td>\n",
       "      <td>135</td>\n",
       "      <td>156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GTG</th>\n",
       "      <td>0.50</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3455</td>\n",
       "      <td>17</td>\n",
       "      <td>78</td>\n",
       "      <td>47</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACG</th>\n",
       "      <td>0.53</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.87</td>\n",
       "      <td>1305</td>\n",
       "      <td>8</td>\n",
       "      <td>39</td>\n",
       "      <td>27</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TTG</th>\n",
       "      <td>0.56</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.90</td>\n",
       "      <td>2835</td>\n",
       "      <td>6</td>\n",
       "      <td>33</td>\n",
       "      <td>25</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ATC</th>\n",
       "      <td>0.51</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.83</td>\n",
       "      <td>1870</td>\n",
       "      <td>8</td>\n",
       "      <td>25</td>\n",
       "      <td>17</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ATT</th>\n",
       "      <td>0.64</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.87</td>\n",
       "      <td>2394</td>\n",
       "      <td>6</td>\n",
       "      <td>13</td>\n",
       "      <td>17</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ATA</th>\n",
       "      <td>0.36</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.64</td>\n",
       "      <td>1339</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AGG</th>\n",
       "      <td>0.14</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.58</td>\n",
       "      <td>5020</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAG</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>4054</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "ScoreType        f1   prc   rec   bac      TN   FN    FP    TP     P\n",
       "Dataset Codon                                                       \n",
       "Test    All    0.61  0.48  0.83  0.91   29746   98   526   486   584\n",
       "        CTG    0.64  0.50  0.88  0.93    5502   23   173   171   194\n",
       "        ATG    0.62  0.48  0.88  0.90    1783   20   163   150   170\n",
       "        GTG    0.63  0.51  0.81  0.90    3733   16    65    69    85\n",
       "        ACG    0.60  0.47  0.82  0.89    1376    8    41    36    44\n",
       "        TTG    0.58  0.51  0.68  0.84    3032   14    29    30    44\n",
       "        ATC    0.68  0.57  0.84  0.92    1907    4    16    21    25\n",
       "        ATT    0.37  0.26  0.60  0.79    2336    6    25     9    15\n",
       "        ATA    0.00  0.00  0.00  0.50    1307    4     4     0     4\n",
       "        AAG    0.00  0.00  0.00  0.50    3758    2     5     0     2\n",
       "        AGG    0.00  0.00  0.00  0.50    5012    1     5     0     1\n",
       "Train   All    0.57  0.43  0.84  0.91  251248  693  4681  3580  4273\n",
       "        CTG    0.60  0.45  0.88  0.92   46597  173  1517  1264  1437\n",
       "        ATG    0.59  0.45  0.87  0.89   15329  187  1483  1210  1397\n",
       "        GTG    0.57  0.44  0.81  0.90   30908  108   595   469   577\n",
       "        ACG    0.55  0.40  0.88  0.92   11096   32   353   236   268\n",
       "        TTG    0.54  0.43  0.74  0.86   25186   67   247   187   254\n",
       "        ATC    0.47  0.33  0.80  0.90   16494   25   210   103   128\n",
       "        ATT    0.49  0.37  0.72  0.86   19506   35   157    92   127\n",
       "        ATA    0.30  0.25  0.38  0.69   11694   25    44    15    40\n",
       "        AGG    0.10  0.08  0.13  0.56   42640   27    48     4    31\n",
       "        AAG    0.00  0.00  0.00  0.50   31798   14    27     0    14\n",
       "Val     All    0.57  0.44  0.82  0.90   29274   97   581   451   548\n",
       "        ATG    0.62  0.48  0.90  0.90    1737   20   198   180   200\n",
       "        CTG    0.57  0.43  0.87  0.92    5265   21   180   135   156\n",
       "        GTG    0.50  0.38  0.73  0.86    3455   17    78    47    64\n",
       "        ACG    0.53  0.41  0.77  0.87    1305    8    39    27    35\n",
       "        TTG    0.56  0.43  0.81  0.90    2835    6    33    25    31\n",
       "        ATC    0.51  0.40  0.68  0.83    1870    8    25    17    25\n",
       "        ATT    0.64  0.57  0.74  0.87    2394    6    13    17    23\n",
       "        ATA    0.36  0.50  0.29  0.64    1339    5     2     2     7\n",
       "        AGG    0.14  0.12  0.17  0.58    5020    5     7     1     6\n",
       "        AAG    0.00  0.00  0.00  0.50    4054    1     6     0     1"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_scores = pd.DataFrame(\n",
    "    unravel_scores(scores), \n",
    "    columns=['Dataset', 'Codon', 'ScoreType', 'ScoreVal']\n",
    ").round(2).pivot(\n",
    "    index=['Dataset', 'Codon'], columns='ScoreType', values='ScoreVal'\n",
    ")\n",
    "\n",
    "for c in ['FN', 'FP', 'TN', 'TP']:\n",
    "    df_scores[c] = df_scores[c].astype(int)\n",
    "\n",
    "df_scores['P'] = df_scores['TP'] + df_scores['FN']\n",
    "\n",
    "df_scores = df_scores.reset_index().sort_values(\n",
    "    ['Dataset', 'P'], ascending=[True, False]\n",
    ").set_index(['Dataset', 'Codon'])[[\n",
    "    'f1', 'prc', 'rec', 'bac', 'TN', 'FN', 'FP', 'TP', 'P'\n",
    "]]\n",
    "\n",
    "df_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7fdf30c-34a1-4c43-a33b-2e487be733f1",
   "metadata": {},
   "source": [
    "Dump score, predictions, and predictions in bed format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "30c37fe8-0c0a-4e26-890e-5ffe1ac8fee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scores.to_csv(BASE / 'prediction_scores_v4.7.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3481bbf8-8e53-4110-bf11-4792ebc37c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cds.to_csv(BASE / 'predictions_5UTR_v4.7.tsv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "21342f96-3108-45d5-8cdd-e00a490d1a7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f9a7a0f47ab454ca780e505685bf2ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred2bed(cds, BASE / 'predictions_5UTR_v4.7.bed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8833c5a0-2ea1-4452-8708-b1062c87cb52",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
